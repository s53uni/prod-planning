{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91e54ce9-7769-4af6-af4b-5c058c5d36b0",
   "metadata": {},
   "source": [
    "## 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68f9ef09-9829-4f00-baca-5a335bb35d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 라이브러리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "### 한글 처리\n",
    "plt.rc(\"font\", family = \"Malgun Gothic\")\n",
    "\n",
    "### 기호 처리\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33c6dc66-e276-439e-963b-8be762f3ce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 정규화 패키지\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "### 모델 관련 패키지\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from os import listdir\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "import platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2fa39e-29b0-4f1b-a262-f90b66db3799",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b544afa4-b60a-4cd9-9f6f-db66cb0e145b",
   "metadata": {},
   "source": [
    "## 데이터 확인 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b393452-4c6a-4d15-bdcc-e17a7cd90b46",
   "metadata": {},
   "source": [
    "1. 원본 데이터는 사람이 작성한 발주 수량 예측 데이터임\n",
    "2. 모델 학습을 통해 수요를 예측하면 오차를 줄일 수 있을 것으로 가정함\n",
    "3. 시각화를 통해 긴급 발주되는 부품이 있음을 확인함\n",
    "4. 긴급 발주 부품은 발주 수량 예측이 어려울 것으로 판단하여 일관성 있게 발주되는 부품 중 5개를 추출하여 학습해보기로 결정함\n",
    "5. 이전 시간 단계의 정보를 기억하고 활용하여 좋은 성능을 보이는 LSTM 모델과, 회귀 모델 중 과적합을 방지하는데 용이한 앙상블 모델을 사용하며, 비교 후 가장 오차가 적은 모델을 선정할 계획"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6806d2ac-6539-43e6-b3a8-1f036126d229",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be42136a-02cb-46a8-bafe-24516e170764",
   "metadata": {},
   "source": [
    "## LSTM 모델 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b4c21c-9f71-49cc-ada8-8693fccc79f4",
   "metadata": {},
   "source": [
    "### 1. 데이터 불러오기 함수(getData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6762a92b-c8ce-48a0-9acf-b29268424184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(part) :\n",
    "    ### 데이터 불러오기\n",
    "    data = pd.read_csv(\"./data_new/01_전처리후_파트별_데이터/part{}_data.csv\".format(part))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad30d477-845c-498a-8c9c-0b300f3df4cf",
   "metadata": {},
   "source": [
    "### 2. 주요 변수 선택 함수(getCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22fec00c-85f5-45d7-8e61-02dfcc8c73c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCols(data, num) :\n",
    "    ### 주요 변수 선택 및 저장\n",
    "    data = data.iloc[:, [1, num+1, num+2, num+3]].reset_index(drop=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd0e8e-057f-4d7f-b8e1-2bb4b7c13c53",
   "metadata": {},
   "source": [
    "### 3. 독립/종속변수 함수(to_timeseries_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7584d65e-186e-475a-b30a-2ba9d2dde282",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 독립변수와 종속변수 만드는 함수\n",
    "def to_timeseries_data(data, lookback, delay):\n",
    "    \n",
    "    output_len = len(data)-(lookback+delay)+1 # N=total_length-(3+3)+1\n",
    "    n_feature = data.shape[-1] # =4\n",
    "    \n",
    "    inputs = np.zeros((output_len, lookback, n_feature)) # (N,3,4)\n",
    "    targets = np.zeros((output_len,)) # (N,)\n",
    "    \n",
    "    for i in range(output_len):\n",
    "        inputs[i] = data.iloc[i:i+lookback, :]\n",
    "        targets[i] = data.iloc[i+lookback+delay-1, 0]\n",
    "        \n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bec268c-03b6-452a-8071-606448b7f870",
   "metadata": {},
   "source": [
    "### 4. 데이터 분리 및 정규화 함수(getSplitData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15b1408b-576a-4372-8239-95eacea74494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSplitData(data, num) :\n",
    "    ### 사용자 정의 함수 적용\n",
    "    X_part, y_part = to_timeseries_data(data, 3, num)\n",
    "\n",
    "    print(\"X의 형태: \", X_part.shape)\n",
    "    print(\"y의 형태: \", y_part.shape)\n",
    "    \n",
    "    ### 데이터셋 분리\n",
    "    X_train_part, X_val_part, X_test_part = np.split(X_part, [int(0.7*len(X_part)), int(0.8*len(X_part))])\n",
    "    y_train_part, y_val_part, y_test_part = np.split(y_part, [int(0.7*len(y_part)), int(0.8*len(y_part))])\n",
    "\n",
    "    ### 분리 이후 데이터 형태\n",
    "    print(\"X 학습: {}, X 검증: {}, X 평가: {}\".format(X_train_part.shape,X_val_part.shape,X_test_part.shape))\n",
    "    print(\"y 학습: {}, y 검증: {}, y 평가: {}\".format(y_train_part.shape,y_val_part.shape,y_test_part.shape))\n",
    "    \n",
    "    ### 데이터 정규화\n",
    "    Xscaler_part = StandardScaler()\n",
    "    X_train_part = Xscaler_part.fit_transform(X_train_part.reshape(-1, X_train_part.shape[-1])).reshape(X_train_part.shape)\n",
    "    X_val_part = Xscaler_part.transform(X_val_part.reshape(-1, X_val_part.shape[-1])).reshape(X_val_part.shape)\n",
    "    X_test_part = Xscaler_part.transform(X_test_part.reshape(-1, X_test_part.shape[-1])).reshape(X_test_part.shape)\n",
    "    X_list = [Xscaler_part, X_train_part, X_val_part, X_test_part]\n",
    "    \n",
    "    yscaler_part = StandardScaler()\n",
    "    y_train_part = yscaler_part.fit_transform(y_train_part.reshape(-1,1))\n",
    "    y_val_part = yscaler_part.transform(y_val_part.reshape(-1,1))\n",
    "    y_test_part = yscaler_part.transform(y_test_part.reshape(-1,1))\n",
    "    y_list = [yscaler_part, y_train_part, y_val_part, y_test_part]\n",
    "    \n",
    "    return X_list, y_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ac1751-49b9-44d5-a482-1424b6bdd94e",
   "metadata": {},
   "source": [
    "### 5. LSTM 모델 함수(getLSTMModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "198659e1-d016-4963-8c0a-403d23ae442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLSTMModel(part, num, X_list, y_list) :\n",
    "    ### 신경망 모델 생성하기\n",
    "    model = Sequential()\n",
    "    \n",
    "    ### LSTM 계층 추가하기\n",
    "    model.add(LSTM(8, dropout=0.2, activation='leaky_relu', input_shape=(3,4), return_sequences=True))\n",
    "    model.add(LSTM(8, dropout=0.2, activation='leaky_relu'))\n",
    "    \n",
    "    ### 출력 계층 추가하기\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    ### 모델 상태 확인하기\n",
    "    model.summary()\n",
    "    \n",
    "    ### 모델 설정하기\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    ### 모델 저장 경로 지정\n",
    "    model_path = './models/part{}_d{}_lstm.h5'.format(part, num)\n",
    "\n",
    "    ### 콜백 함수 지정\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=15),\n",
    "                ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=0, save_best_only=True)]\n",
    "    \n",
    "    ### 모델 훈련시키기\n",
    "    history = model.fit(X_list[1], y_list[1], epochs=100, batch_size=4, validation_data=(X_list[2], y_list[2]),\n",
    "                        callbacks=callbacks)\n",
    "    \n",
    "    ### 모델 불러오기\n",
    "    best_model = load_model('./models/part{}_d{}_lstm.h5'.format(part, num))\n",
    "    \n",
    "    ### 테스트 데이터로 성능 평가\n",
    "    best_model.evaluate(X_list[3], y_list[3])\n",
    "    \n",
    "    ### 테스트 데이터로 예측하기\n",
    "    y_pred_part = best_model.predict(X_list[3])\n",
    "    \n",
    "    ### 예측값을 기존 값 범위로 역변환\n",
    "    y_pred_part_inv = y_list[0].inverse_transform(y_pred_part)\n",
    "    y_test_part_inv = y_list[0].inverse_transform(y_list[3])\n",
    "    \n",
    "    ### mae, mse, rmse 계산\n",
    "    mae = mean_absolute_error(y_test_part_inv, y_pred_part_inv)\n",
    "    mse = mean_squared_error(y_test_part_inv, y_pred_part_inv)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    ### 모델 성능 계산\n",
    "    train_eva = best_model.evaluate(X_list[1], y_list[1])\n",
    "    val_eva = best_model.evaluate(X_list[2], y_list[2])\n",
    "    test_eva = best_model.evaluate(X_list[3], y_list[3])\n",
    "    \n",
    "    result_list = [part, num, train_eva, val_eva, test_eva, mae, mse, rmse]\n",
    "    \n",
    "    return result_list, y_test_part_inv, y_pred_part_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "90f61090-5392-4303-9041-2ddf36f9bcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (46, 3, 4)\n",
      "y의 형태:  (46,)\n",
      "X 학습: (32, 3, 4), X 검증: (4, 3, 4), X 평가: (10, 3, 4)\n",
      "y 학습: (32,), y 검증: (4,), y 평가: (10,)\n",
      "Model: \"sequential_144\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_288 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_289 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 62ms/step - loss: 0.9783 - val_loss: 0.1620\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9791 - val_loss: 0.1626\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9891 - val_loss: 0.1578\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9805 - val_loss: 0.1558\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9814 - val_loss: 0.1552\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9780 - val_loss: 0.1569\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9786 - val_loss: 0.1563\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9855 - val_loss: 0.1571\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9709 - val_loss: 0.1517\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9813 - val_loss: 0.1513\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9906 - val_loss: 0.1497\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9802 - val_loss: 0.1486\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9678 - val_loss: 0.1501\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9544 - val_loss: 0.1570\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0040 - val_loss: 0.1590\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9784 - val_loss: 0.1569\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9648 - val_loss: 0.1561\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9650 - val_loss: 0.1562\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9699 - val_loss: 0.1572\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.9611 - val_loss: 0.1619\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9611 - val_loss: 0.1710\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9508 - val_loss: 0.1695\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9466 - val_loss: 0.1771\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9556 - val_loss: 0.1797\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9667 - val_loss: 0.1860\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9577 - val_loss: 0.1869\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9392 - val_loss: 0.1933\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 0.1499\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 0.9675\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1486\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1499\n",
      "X의 형태:  (45, 3, 4)\n",
      "y의 형태:  (45,)\n",
      "X 학습: (31, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (31,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_145\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_290 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_291 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 4s 71ms/step - loss: 0.9977 - val_loss: 0.0467\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9986 - val_loss: 0.0484\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9905 - val_loss: 0.0503\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0016 - val_loss: 0.0499\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9956 - val_loss: 0.0502\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9875 - val_loss: 0.0511\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9854 - val_loss: 0.0525\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9851 - val_loss: 0.0530\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9810 - val_loss: 0.0529\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9931 - val_loss: 0.0534\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9917 - val_loss: 0.0542\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9803 - val_loss: 0.0567\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9695 - val_loss: 0.0570\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9868 - val_loss: 0.0573\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9744 - val_loss: 0.0581\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9587 - val_loss: 0.0587\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 0.0872\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9944\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0467\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0872\n",
      "X의 형태:  (44, 3, 4)\n",
      "y의 형태:  (44,)\n",
      "X 학습: (30, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_146\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_292 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_293 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 68ms/step - loss: 0.9713 - val_loss: 0.0814\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9792 - val_loss: 0.0795\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9765 - val_loss: 0.0756\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9669 - val_loss: 0.0732\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9687 - val_loss: 0.0721\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9642 - val_loss: 0.0702\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9275 - val_loss: 0.0692\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9429 - val_loss: 0.0666\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9332 - val_loss: 0.0643\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9376 - val_loss: 0.0625\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8987 - val_loss: 0.0607\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9147 - val_loss: 0.0579\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8919 - val_loss: 0.0543\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9190 - val_loss: 0.0522\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9105 - val_loss: 0.0502\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8715 - val_loss: 0.0467\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9011 - val_loss: 0.0446\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9096 - val_loss: 0.0419\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8634 - val_loss: 0.0393\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9330 - val_loss: 0.0374\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8790 - val_loss: 0.0364\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8712 - val_loss: 0.0341\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8462 - val_loss: 0.0328\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8364 - val_loss: 0.0306\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8318 - val_loss: 0.0287\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8816 - val_loss: 0.0283\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7906 - val_loss: 0.0277\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8736 - val_loss: 0.0283\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8831 - val_loss: 0.0264\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8172 - val_loss: 0.0252\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8152 - val_loss: 0.0225\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7657 - val_loss: 0.0213\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8132 - val_loss: 0.0197\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8004 - val_loss: 0.0200\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8152 - val_loss: 0.0196\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8157 - val_loss: 0.0176\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7923 - val_loss: 0.0170\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8101 - val_loss: 0.0164\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7868 - val_loss: 0.0162\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7775 - val_loss: 0.0148\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7930 - val_loss: 0.0146\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.8130 - val_loss: 0.0144\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8378 - val_loss: 0.0155\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8843 - val_loss: 0.0152\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6986 - val_loss: 0.0149\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7831 - val_loss: 0.0137\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6858 - val_loss: 0.0143\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.7869 - val_loss: 0.0143\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6404 - val_loss: 0.0134\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6068 - val_loss: 0.0125\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7272 - val_loss: 0.0119\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6064 - val_loss: 0.0108\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4990 - val_loss: 0.0105\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.6627 - val_loss: 0.0098\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5570 - val_loss: 0.0088\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6346 - val_loss: 0.0095\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5220 - val_loss: 0.0105\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5934 - val_loss: 0.0127\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4012 - val_loss: 0.0162\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.7598 - val_loss: 0.0186\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4297 - val_loss: 0.0229\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5943 - val_loss: 0.0206\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4397 - val_loss: 0.0205\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2069 - val_loss: 0.0217\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3370 - val_loss: 0.0236\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4824 - val_loss: 0.0252\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6977 - val_loss: 0.0257\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6030 - val_loss: 0.0284\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1356 - val_loss: 0.0293\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2639 - val_loss: 0.0317\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.0777\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5607\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0088\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0777\n",
      "X의 형태:  (43, 3, 4)\n",
      "y의 형태:  (43,)\n",
      "X 학습: (30, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_147\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_294 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_295 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 4s 68ms/step - loss: 0.9959 - val_loss: 0.0448\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9708 - val_loss: 0.0445\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9652 - val_loss: 0.0432\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9648 - val_loss: 0.0430\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9523 - val_loss: 0.0434\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9421 - val_loss: 0.0431\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9499 - val_loss: 0.0440\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9703 - val_loss: 0.0434\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9668 - val_loss: 0.0437\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9528 - val_loss: 0.0452\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9443 - val_loss: 0.0451\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9222 - val_loss: 0.0454\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9343 - val_loss: 0.0462\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9223 - val_loss: 0.0472\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9371 - val_loss: 0.0478\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9475 - val_loss: 0.0465\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9159 - val_loss: 0.0483\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9232 - val_loss: 0.0468\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9246 - val_loss: 0.0470\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.0764\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9676\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0430\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0764\n",
      "X의 형태:  (42, 3, 4)\n",
      "y의 형태:  (42,)\n",
      "X 학습: (29, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (29,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_148\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_296 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_297 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 70ms/step - loss: 1.0174 - val_loss: 0.0553\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.0274 - val_loss: 0.0549\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0075 - val_loss: 0.0553\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0215 - val_loss: 0.0564\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0019 - val_loss: 0.0569\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0132 - val_loss: 0.0581\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0100 - val_loss: 0.0584\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.0107 - val_loss: 0.0587\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0051 - val_loss: 0.0594\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.0009 - val_loss: 0.0603\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0095 - val_loss: 0.0612\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0031 - val_loss: 0.0622\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0021 - val_loss: 0.0632\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9974 - val_loss: 0.0639\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0071 - val_loss: 0.0649\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0063 - val_loss: 0.0653\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0051 - val_loss: 0.0663\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.0823\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0121\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0549\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0823\n",
      "X의 형태:  (41, 3, 4)\n",
      "y의 형태:  (41,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_149\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_298 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_299 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 2s 73ms/step - loss: 1.0020 - val_loss: 0.0576\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.0034 - val_loss: 0.0602\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9928 - val_loss: 0.0622\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.0024 - val_loss: 0.0640\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.0129 - val_loss: 0.0648\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9914 - val_loss: 0.0650\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9893 - val_loss: 0.0661\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9949 - val_loss: 0.0674\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9949 - val_loss: 0.0690\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9973 - val_loss: 0.0698\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9969 - val_loss: 0.0706\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9946 - val_loss: 0.0714\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9899 - val_loss: 0.0720\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9854 - val_loss: 0.0728\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9802 - val_loss: 0.0739\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9901 - val_loss: 0.0760\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 0.0859\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9975\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0576\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0859\n",
      "X의 형태:  (40, 3, 4)\n",
      "y의 형태:  (40,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (8, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (8,)\n",
      "Model: \"sequential_150\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_300 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_301 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 3s 76ms/step - loss: 1.0034 - val_loss: 0.0207\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0021 - val_loss: 0.0213\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.0038 - val_loss: 0.0217\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9974 - val_loss: 0.0219\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.9937 - val_loss: 0.0220\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9997 - val_loss: 0.0222\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9947 - val_loss: 0.0227\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9963 - val_loss: 0.0229\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9938 - val_loss: 0.0235\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9923 - val_loss: 0.0239\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9911 - val_loss: 0.0244\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9912 - val_loss: 0.0251\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9900 - val_loss: 0.0256\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9937 - val_loss: 0.0261\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9874 - val_loss: 0.0266\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9854 - val_loss: 0.0270\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.0776\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0006\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0207\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0776\n",
      "X의 형태:  (46, 3, 4)\n",
      "y의 형태:  (46,)\n",
      "X 학습: (32, 3, 4), X 검증: (4, 3, 4), X 평가: (10, 3, 4)\n",
      "y 학습: (32,), y 검증: (4,), y 평가: (10,)\n",
      "Model: \"sequential_151\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_302 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_303 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 2s 64ms/step - loss: 0.9763 - val_loss: 2.5494\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9792 - val_loss: 2.5484\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.9686 - val_loss: 2.5511\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9391 - val_loss: 2.5757\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9324 - val_loss: 2.6123\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9684 - val_loss: 2.6363\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9370 - val_loss: 2.6544\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9789 - val_loss: 2.6424\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9385 - val_loss: 2.6636\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9522 - val_loss: 2.6578\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8814 - val_loss: 2.6896\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9145 - val_loss: 2.6973\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8873 - val_loss: 2.6971\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.8942 - val_loss: 2.7468\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.8656 - val_loss: 2.7466\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.8480 - val_loss: 2.8345\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8772 - val_loss: 2.8974\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.7135\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.9662\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.5484\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7135\n",
      "X의 형태:  (45, 3, 4)\n",
      "y의 형태:  (45,)\n",
      "X 학습: (31, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (31,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_152\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_304 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_305 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 70ms/step - loss: 0.9892 - val_loss: 1.8657\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9712 - val_loss: 1.8676\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9813 - val_loss: 1.8705\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9731 - val_loss: 1.8708\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9757 - val_loss: 1.8665\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9572 - val_loss: 1.8658\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9469 - val_loss: 1.8727\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9393 - val_loss: 1.8776\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9545 - val_loss: 1.8716\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9421 - val_loss: 1.8671\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9070 - val_loss: 1.8665\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9168 - val_loss: 1.8815\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8907 - val_loss: 1.8859\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9190 - val_loss: 1.8824\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8806 - val_loss: 1.8863\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8707 - val_loss: 1.8934\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.7750\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9786\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8657\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7750\n",
      "X의 형태:  (44, 3, 4)\n",
      "y의 형태:  (44,)\n",
      "X 학습: (30, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_153\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_306 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_307 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 71ms/step - loss: 0.9975 - val_loss: 1.8085\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0003 - val_loss: 1.8129\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9917 - val_loss: 1.8077\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9924 - val_loss: 1.8040\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.0090 - val_loss: 1.8003\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0042 - val_loss: 1.8013\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9951 - val_loss: 1.8096\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9874 - val_loss: 1.8202\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9755 - val_loss: 1.8200\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9969 - val_loss: 1.8250\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9647 - val_loss: 1.8257\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9737 - val_loss: 1.8284\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9570 - val_loss: 1.8216\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9855 - val_loss: 1.8223\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9172 - val_loss: 1.8152\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9459 - val_loss: 1.8030\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9364 - val_loss: 1.7953\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9278 - val_loss: 1.7952\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9497 - val_loss: 1.7932\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9196 - val_loss: 1.7996\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9191 - val_loss: 1.8175\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9408 - val_loss: 1.8134\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9477 - val_loss: 1.8236\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8802 - val_loss: 1.8330\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8843 - val_loss: 1.8494\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8963 - val_loss: 1.8806\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8443 - val_loss: 1.8963\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8801 - val_loss: 1.9196\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8939 - val_loss: 1.9153\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8794 - val_loss: 1.9656\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9135 - val_loss: 2.0030\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8962 - val_loss: 2.0126\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8342 - val_loss: 2.0212\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8320 - val_loss: 2.0116\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.6341\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9138\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7932\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6341\n",
      "X의 형태:  (43, 3, 4)\n",
      "y의 형태:  (43,)\n",
      "X 학습: (30, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_154\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_308 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_309 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 66ms/step - loss: 1.0463 - val_loss: 1.8633\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0131 - val_loss: 1.8708\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0125 - val_loss: 1.8743\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0063 - val_loss: 1.8872\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0124 - val_loss: 1.8926\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0006 - val_loss: 1.9007\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0147 - val_loss: 1.9163\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0003 - val_loss: 1.9210\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9849 - val_loss: 1.9155\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9898 - val_loss: 1.9252\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9971 - val_loss: 1.9188\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9927 - val_loss: 1.9236\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9753 - val_loss: 1.9215\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9719 - val_loss: 1.9201\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9640 - val_loss: 1.9149\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9703 - val_loss: 1.9041\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 0.8204\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0143\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.8633\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8204\n",
      "X의 형태:  (42, 3, 4)\n",
      "y의 형태:  (42,)\n",
      "X 학습: (29, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (29,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_155\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_310 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_311 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 67ms/step - loss: 0.9841 - val_loss: 2.0319\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9971 - val_loss: 2.0302\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9981 - val_loss: 2.0300\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9787 - val_loss: 2.0362\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9740 - val_loss: 2.0479\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9852 - val_loss: 2.0698\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9862 - val_loss: 2.0914\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9781 - val_loss: 2.0958\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9573 - val_loss: 2.1034\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9747 - val_loss: 2.1102\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9836 - val_loss: 2.1194\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9929 - val_loss: 2.1347\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9672 - val_loss: 2.1471\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9935 - val_loss: 2.1426\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9660 - val_loss: 2.1593\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9627 - val_loss: 2.1859\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9640 - val_loss: 2.2119\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9756 - val_loss: 2.2144\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6597\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9930\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.0300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6597\n",
      "X의 형태:  (41, 3, 4)\n",
      "y의 형태:  (41,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_156\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_312 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_313 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 2s 65ms/step - loss: 1.0102 - val_loss: 1.9120\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.9960 - val_loss: 1.9078\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0058 - val_loss: 1.9051\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9953 - val_loss: 1.9064\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0003 - val_loss: 1.9066\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9912 - val_loss: 1.9054\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9832 - val_loss: 1.9027\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9958 - val_loss: 1.9054\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9820 - val_loss: 1.9069\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9937 - val_loss: 1.9065\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9790 - val_loss: 1.9053\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9892 - val_loss: 1.9054\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9862 - val_loss: 1.9057\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9801 - val_loss: 1.9064\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9649 - val_loss: 1.9082\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9544 - val_loss: 1.9120\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9798 - val_loss: 1.9123\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9408 - val_loss: 1.9157\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9546 - val_loss: 1.9217\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9591 - val_loss: 1.9255\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9687 - val_loss: 1.9274\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9336 - val_loss: 1.9365\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.6595\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9896\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.9027\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6595\n",
      "X의 형태:  (40, 3, 4)\n",
      "y의 형태:  (40,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (8, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (8,)\n",
      "Model: \"sequential_157\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_314 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_315 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 3s 76ms/step - loss: 1.0134 - val_loss: 1.2165\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0123 - val_loss: 1.2207\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.0022 - val_loss: 1.2267\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.0000 - val_loss: 1.2281\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9962 - val_loss: 1.2294\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0028 - val_loss: 1.2308\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0025 - val_loss: 1.2330\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9958 - val_loss: 1.2345\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9892 - val_loss: 1.2364\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9982 - val_loss: 1.2405\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9958 - val_loss: 1.2410\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9987 - val_loss: 1.2424\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.9848 - val_loss: 1.2427\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9939 - val_loss: 1.2493\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9859 - val_loss: 1.2515\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9945 - val_loss: 1.2524\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.8895\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0072\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2165\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8895\n",
      "X의 형태:  (46, 3, 4)\n",
      "y의 형태:  (46,)\n",
      "X 학습: (32, 3, 4), X 검증: (4, 3, 4), X 평가: (10, 3, 4)\n",
      "y 학습: (32,), y 검증: (4,), y 평가: (10,)\n",
      "Model: \"sequential_158\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_316 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_317 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 2s 69ms/step - loss: 0.9954 - val_loss: 0.0250\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0134 - val_loss: 0.0250\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.0118 - val_loss: 0.0258\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.9930 - val_loss: 0.0260\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9811 - val_loss: 0.0262\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0124 - val_loss: 0.0263\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9753 - val_loss: 0.0265\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9843 - val_loss: 0.0260\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9661 - val_loss: 0.0264\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9607 - val_loss: 0.0251\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9684 - val_loss: 0.0239\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9365 - val_loss: 0.0235\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9257 - val_loss: 0.0219\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9333 - val_loss: 0.0194\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9349 - val_loss: 0.0178\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9489 - val_loss: 0.0168\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9242 - val_loss: 0.0154\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8498 - val_loss: 0.0139\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9366 - val_loss: 0.0125\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9094 - val_loss: 0.0107\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8348 - val_loss: 0.0099\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8353 - val_loss: 0.0099\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8190 - val_loss: 0.0086\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8368 - val_loss: 0.0083\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8988 - val_loss: 0.0078\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9161 - val_loss: 0.0089\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.8136 - val_loss: 0.0102\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7553 - val_loss: 0.0110\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.8086 - val_loss: 0.0112\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7735 - val_loss: 0.0113\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8311 - val_loss: 0.0120\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7511 - val_loss: 0.0134\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8236 - val_loss: 0.0141\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7423 - val_loss: 0.0220\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7668 - val_loss: 0.0259\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7969 - val_loss: 0.0281\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8277 - val_loss: 0.0298\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8064 - val_loss: 0.0315\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7992 - val_loss: 0.0357\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8377 - val_loss: 0.0402\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.3650\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.7996\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0078\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3650\n",
      "X의 형태:  (45, 3, 4)\n",
      "y의 형태:  (45,)\n",
      "X 학습: (31, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (31,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_159\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_318 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_319 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 68ms/step - loss: 1.0111 - val_loss: 0.0722\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9889 - val_loss: 0.0707\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0043 - val_loss: 0.0677\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9936 - val_loss: 0.0683\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0021 - val_loss: 0.0677\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9994 - val_loss: 0.0672\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9978 - val_loss: 0.0657\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0015 - val_loss: 0.0656\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9850 - val_loss: 0.0662\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9912 - val_loss: 0.0660\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9864 - val_loss: 0.0655\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9914 - val_loss: 0.0635\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0055 - val_loss: 0.0630\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9976 - val_loss: 0.0627\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9861 - val_loss: 0.0618\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9847 - val_loss: 0.0606\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9882 - val_loss: 0.0599\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9894 - val_loss: 0.0584\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9848 - val_loss: 0.0579\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9875 - val_loss: 0.0580\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9708 - val_loss: 0.0569\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9592 - val_loss: 0.0567\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9949 - val_loss: 0.0548\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9717 - val_loss: 0.0534\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9899 - val_loss: 0.0530\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9639 - val_loss: 0.0519\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9930 - val_loss: 0.0505\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9854 - val_loss: 0.0502\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9767 - val_loss: 0.0487\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9739 - val_loss: 0.0493\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9684 - val_loss: 0.0475\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9576 - val_loss: 0.0472\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9597 - val_loss: 0.0451\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9740 - val_loss: 0.0441\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9776 - val_loss: 0.0444\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9769 - val_loss: 0.0422\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9554 - val_loss: 0.0418\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9420 - val_loss: 0.0407\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9352 - val_loss: 0.0392\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9397 - val_loss: 0.0383\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9459 - val_loss: 0.0370\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9416 - val_loss: 0.0347\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9223 - val_loss: 0.0316\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8889 - val_loss: 0.0290\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8735 - val_loss: 0.0268\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9218 - val_loss: 0.0231\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8792 - val_loss: 0.0203\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9197 - val_loss: 0.0182\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9439 - val_loss: 0.0150\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8748 - val_loss: 0.0117\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8161 - val_loss: 0.0087\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9077 - val_loss: 0.0065\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7590 - val_loss: 0.0057\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7708 - val_loss: 0.0071\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.8256 - val_loss: 0.0106\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8272 - val_loss: 0.0138\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8526 - val_loss: 0.0296\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6575 - val_loss: 0.0454\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6510 - val_loss: 0.0405\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6445 - val_loss: 0.0593\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6406 - val_loss: 0.0707\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6390 - val_loss: 0.0603\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7317 - val_loss: 0.0224\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6854 - val_loss: 0.0189\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6469 - val_loss: 0.0209\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6549 - val_loss: 0.0211\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6836 - val_loss: 0.0336\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.8199 - val_loss: 0.0437\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 0.7886\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7760\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0057\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7886\n",
      "X의 형태:  (44, 3, 4)\n",
      "y의 형태:  (44,)\n",
      "X 학습: (30, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_160\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_320 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_321 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_160 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 4s 63ms/step - loss: 0.9912 - val_loss: 0.0521\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9769 - val_loss: 0.0509\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9898 - val_loss: 0.0519\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9637 - val_loss: 0.0523\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9797 - val_loss: 0.0521\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9769 - val_loss: 0.0515\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9599 - val_loss: 0.0502\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9645 - val_loss: 0.0493\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9563 - val_loss: 0.0476\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9656 - val_loss: 0.0475\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9689 - val_loss: 0.0481\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9781 - val_loss: 0.0482\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9218 - val_loss: 0.0483\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9765 - val_loss: 0.0482\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9690 - val_loss: 0.0488\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9674 - val_loss: 0.0500\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9225 - val_loss: 0.0511\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9398 - val_loss: 0.0522\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9458 - val_loss: 0.0544\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9458 - val_loss: 0.0560\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9326 - val_loss: 0.0550\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8965 - val_loss: 0.0553\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8939 - val_loss: 0.0573\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8995 - val_loss: 0.0603\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9094 - val_loss: 0.0626\n",
      "1/1 [==============================] - 0s 359ms/step - loss: 0.7686\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9589\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0475\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7686\n",
      "X의 형태:  (43, 3, 4)\n",
      "y의 형태:  (43,)\n",
      "X 학습: (30, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_161\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_322 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_323 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 70ms/step - loss: 1.0677 - val_loss: 0.0146\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0651 - val_loss: 0.0194\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0438 - val_loss: 0.0251\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0446 - val_loss: 0.0294\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0068 - val_loss: 0.0330\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.0536 - val_loss: 0.0371\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0197 - val_loss: 0.0397\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0157 - val_loss: 0.0441\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0099 - val_loss: 0.0475\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0175 - val_loss: 0.0492\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0185 - val_loss: 0.0536\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0115 - val_loss: 0.0557\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0027 - val_loss: 0.0573\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0031 - val_loss: 0.0593\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9919 - val_loss: 0.0607\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.0033 - val_loss: 0.0627\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.4425\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0452\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0146\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4425\n",
      "X의 형태:  (42, 3, 4)\n",
      "y의 형태:  (42,)\n",
      "X 학습: (29, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (29,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_162\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_324 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_325 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 4s 69ms/step - loss: 1.0111 - val_loss: 0.0378\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9992 - val_loss: 0.0410\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0110 - val_loss: 0.0430\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9993 - val_loss: 0.0439\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0014 - val_loss: 0.0466\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9927 - val_loss: 0.0474\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.0033 - val_loss: 0.0489\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.0008 - val_loss: 0.0504\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9958 - val_loss: 0.0524\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9875 - val_loss: 0.0552\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9874 - val_loss: 0.0572\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9872 - val_loss: 0.0583\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9819 - val_loss: 0.0599\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9904 - val_loss: 0.0632\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9804 - val_loss: 0.0668\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9764 - val_loss: 0.0675\n",
      "1/1 [==============================] - 0s 411ms/step - loss: 0.5984\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0074\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0378\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5984\n",
      "X의 형태:  (41, 3, 4)\n",
      "y의 형태:  (41,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_163\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_326 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_327 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 2s 72ms/step - loss: 0.9999 - val_loss: 0.0242\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0011 - val_loss: 0.0260\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9952 - val_loss: 0.0269\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9934 - val_loss: 0.0264\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9955 - val_loss: 0.0266\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9918 - val_loss: 0.0265\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9934 - val_loss: 0.0272\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9870 - val_loss: 0.0272\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9901 - val_loss: 0.0266\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9957 - val_loss: 0.0274\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9891 - val_loss: 0.0281\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9883 - val_loss: 0.0279\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9829 - val_loss: 0.0293\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9806 - val_loss: 0.0290\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9850 - val_loss: 0.0301\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9833 - val_loss: 0.0298\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.5572\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9995\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0242\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5572\n",
      "X의 형태:  (40, 3, 4)\n",
      "y의 형태:  (40,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (8, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (8,)\n",
      "Model: \"sequential_164\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_328 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_329 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 2s 77ms/step - loss: 0.9979 - val_loss: 0.0351\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9986 - val_loss: 0.0358\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9869 - val_loss: 0.0363\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9945 - val_loss: 0.0361\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9844 - val_loss: 0.0373\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9895 - val_loss: 0.0376\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9883 - val_loss: 0.0381\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9842 - val_loss: 0.0390\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9846 - val_loss: 0.0388\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9768 - val_loss: 0.0397\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9786 - val_loss: 0.0411\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9738 - val_loss: 0.0419\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9693 - val_loss: 0.0440\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9622 - val_loss: 0.0453\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9647 - val_loss: 0.0480\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9797 - val_loss: 0.0493\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.6732\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9925\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0351\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6732\n",
      "X의 형태:  (46, 3, 4)\n",
      "y의 형태:  (46,)\n",
      "X 학습: (32, 3, 4), X 검증: (4, 3, 4), X 평가: (10, 3, 4)\n",
      "y 학습: (32,), y 검증: (4,), y 평가: (10,)\n",
      "Model: \"sequential_165\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_330 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_331 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 62ms/step - loss: 0.9864 - val_loss: 0.0450\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9994 - val_loss: 0.0453\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9877 - val_loss: 0.0461\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0090 - val_loss: 0.0455\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9869 - val_loss: 0.0452\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9753 - val_loss: 0.0447\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9783 - val_loss: 0.0447\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9674 - val_loss: 0.0436\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9580 - val_loss: 0.0430\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9834 - val_loss: 0.0420\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9864 - val_loss: 0.0404\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9452 - val_loss: 0.0397\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9480 - val_loss: 0.0385\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9448 - val_loss: 0.0359\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9559 - val_loss: 0.0350\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9648 - val_loss: 0.0342\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9534 - val_loss: 0.0336\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9419 - val_loss: 0.0319\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9326 - val_loss: 0.0308\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9123 - val_loss: 0.0289\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8914 - val_loss: 0.0285\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8761 - val_loss: 0.0292\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8786 - val_loss: 0.0277\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8950 - val_loss: 0.0275\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8434 - val_loss: 0.0250\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.8741 - val_loss: 0.0252\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7960 - val_loss: 0.0268\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7883 - val_loss: 0.0288\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7742 - val_loss: 0.0306\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7725 - val_loss: 0.0319\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8170 - val_loss: 0.0342\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6862 - val_loss: 0.0397\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7695 - val_loss: 0.0452\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7995 - val_loss: 0.0480\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7300 - val_loss: 0.0492\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6669 - val_loss: 0.0513\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7557 - val_loss: 0.0571\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7043 - val_loss: 0.0603\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6098 - val_loss: 0.0625\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7164 - val_loss: 0.0674\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 0.0077\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.8255\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0077\n",
      "X의 형태:  (45, 3, 4)\n",
      "y의 형태:  (45,)\n",
      "X 학습: (31, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (31,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_166\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_332 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_333 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 74ms/step - loss: 0.9782 - val_loss: 0.0168\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9700 - val_loss: 0.0146\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9734 - val_loss: 0.0124\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9635 - val_loss: 0.0123\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9732 - val_loss: 0.0121\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9397 - val_loss: 0.0113\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9334 - val_loss: 0.0098\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9657 - val_loss: 0.0089\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9311 - val_loss: 0.0087\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9179 - val_loss: 0.0081\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9399 - val_loss: 0.0077\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9521 - val_loss: 0.0067\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9326 - val_loss: 0.0067\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9379 - val_loss: 0.0069\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9382 - val_loss: 0.0068\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9296 - val_loss: 0.0068\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9332 - val_loss: 0.0071\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9444 - val_loss: 0.0071\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9411 - val_loss: 0.0073\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9074 - val_loss: 0.0075\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9145 - val_loss: 0.0077\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9203 - val_loss: 0.0079\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9171 - val_loss: 0.0082\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9004 - val_loss: 0.0083\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9125 - val_loss: 0.0085\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9266 - val_loss: 0.0086\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8950 - val_loss: 0.0086\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.0124\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9206\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0067\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0124\n",
      "X의 형태:  (44, 3, 4)\n",
      "y의 형태:  (44,)\n",
      "X 학습: (30, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_167\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_334 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_335 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 4s 73ms/step - loss: 0.9921 - val_loss: 0.0057\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9867 - val_loss: 0.0051\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9860 - val_loss: 0.0051\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9777 - val_loss: 0.0053\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9692 - val_loss: 0.0060\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9670 - val_loss: 0.0071\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9711 - val_loss: 0.0095\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9560 - val_loss: 0.0110\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9466 - val_loss: 0.0143\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9570 - val_loss: 0.0195\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9620 - val_loss: 0.0253\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9374 - val_loss: 0.0333\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9071 - val_loss: 0.0413\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9186 - val_loss: 0.0514\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9074 - val_loss: 0.0626\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9261 - val_loss: 0.0708\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9319 - val_loss: 0.0719\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9298 - val_loss: 0.0644\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.0047\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9775\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0051\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0047\n",
      "X의 형태:  (43, 3, 4)\n",
      "y의 형태:  (43,)\n",
      "X 학습: (30, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_168\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_336 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_337 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 4s 63ms/step - loss: 1.0068 - val_loss: 0.0231\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0070 - val_loss: 0.0229\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9962 - val_loss: 0.0229\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0001 - val_loss: 0.0225\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9961 - val_loss: 0.0221\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0018 - val_loss: 0.0215\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.0009 - val_loss: 0.0201\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9827 - val_loss: 0.0196\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9844 - val_loss: 0.0190\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.0044 - val_loss: 0.0176\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9899 - val_loss: 0.0172\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9866 - val_loss: 0.0163\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9794 - val_loss: 0.0156\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9806 - val_loss: 0.0147\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9805 - val_loss: 0.0138\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9831 - val_loss: 0.0131\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9792 - val_loss: 0.0120\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0007 - val_loss: 0.0118\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9737 - val_loss: 0.0115\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9491 - val_loss: 0.0110\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9945 - val_loss: 0.0102\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9606 - val_loss: 0.0095\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9705 - val_loss: 0.0091\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9775 - val_loss: 0.0085\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9548 - val_loss: 0.0080\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9752 - val_loss: 0.0073\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9809 - val_loss: 0.0067\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9325 - val_loss: 0.0060\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9481 - val_loss: 0.0057\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9502 - val_loss: 0.0051\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8955 - val_loss: 0.0049\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9322 - val_loss: 0.0054\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9506 - val_loss: 0.0057\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8812 - val_loss: 0.0066\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9485 - val_loss: 0.0081\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9187 - val_loss: 0.0114\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9537 - val_loss: 0.0155\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9102 - val_loss: 0.0192\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8777 - val_loss: 0.0232\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8937 - val_loss: 0.0268\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8957 - val_loss: 0.0283\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8156 - val_loss: 0.0339\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.8871 - val_loss: 0.0368\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.8064 - val_loss: 0.0384\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9081 - val_loss: 0.0388\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8892 - val_loss: 0.0433\n",
      "1/1 [==============================] - 0s 391ms/step - loss: 0.0050\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9368\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0049\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0050\n",
      "X의 형태:  (42, 3, 4)\n",
      "y의 형태:  (42,)\n",
      "X 학습: (29, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (29,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_169\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_338 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_339 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 69ms/step - loss: 1.0292 - val_loss: 0.0302\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0114 - val_loss: 0.0297\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0072 - val_loss: 0.0285\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.0063 - val_loss: 0.0268\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0230 - val_loss: 0.0255\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0225 - val_loss: 0.0226\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9994 - val_loss: 0.0205\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0182 - val_loss: 0.0189\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0091 - val_loss: 0.0183\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.0059 - val_loss: 0.0182\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9952 - val_loss: 0.0177\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9943 - val_loss: 0.0168\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9886 - val_loss: 0.0161\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0045 - val_loss: 0.0161\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9987 - val_loss: 0.0158\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9997 - val_loss: 0.0147\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9880 - val_loss: 0.0136\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9967 - val_loss: 0.0134\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9923 - val_loss: 0.0134\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9929 - val_loss: 0.0137\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9852 - val_loss: 0.0138\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9861 - val_loss: 0.0135\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9717 - val_loss: 0.0126\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9801 - val_loss: 0.0124\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9799 - val_loss: 0.0116\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9720 - val_loss: 0.0114\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9586 - val_loss: 0.0113\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9545 - val_loss: 0.0106\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9743 - val_loss: 0.0106\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9547 - val_loss: 0.0099\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9432 - val_loss: 0.0095\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9432 - val_loss: 0.0092\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9401 - val_loss: 0.0089\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9382 - val_loss: 0.0088\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9491 - val_loss: 0.0085\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9623 - val_loss: 0.0085\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9268 - val_loss: 0.0081\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9506 - val_loss: 0.0080\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9595 - val_loss: 0.0077\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9511 - val_loss: 0.0075\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9279 - val_loss: 0.0077\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9513 - val_loss: 0.0079\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9456 - val_loss: 0.0077\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9427 - val_loss: 0.0080\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9377 - val_loss: 0.0083\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9445 - val_loss: 0.0079\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9444 - val_loss: 0.0085\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9180 - val_loss: 0.0084\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9181 - val_loss: 0.0085\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9539 - val_loss: 0.0083\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9745 - val_loss: 0.0081\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9229 - val_loss: 0.0087\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9089 - val_loss: 0.0089\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9093 - val_loss: 0.0095\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9318 - val_loss: 0.0091\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 0.0050\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9380\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0075\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0050\n",
      "X의 형태:  (41, 3, 4)\n",
      "y의 형태:  (41,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_170\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_340 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_341 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 3s 73ms/step - loss: 1.0129 - val_loss: 0.0082\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.0110 - val_loss: 0.0084\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0106 - val_loss: 0.0083\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0000 - val_loss: 0.0078\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.0015 - val_loss: 0.0075\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9878 - val_loss: 0.0073\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9974 - val_loss: 0.0070\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9932 - val_loss: 0.0067\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9842 - val_loss: 0.0064\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9894 - val_loss: 0.0063\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9873 - val_loss: 0.0062\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9825 - val_loss: 0.0062\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9768 - val_loss: 0.0063\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9696 - val_loss: 0.0067\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9700 - val_loss: 0.0070\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9723 - val_loss: 0.0080\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9614 - val_loss: 0.0084\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9545 - val_loss: 0.0090\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9635 - val_loss: 0.0101\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9587 - val_loss: 0.0109\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9576 - val_loss: 0.0116\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9463 - val_loss: 0.0128\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9578 - val_loss: 0.0131\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9539 - val_loss: 0.0146\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9479 - val_loss: 0.0147\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9321 - val_loss: 0.0152\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 0.0039\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9754\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0062\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0039\n",
      "X의 형태:  (40, 3, 4)\n",
      "y의 형태:  (40,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (8, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (8,)\n",
      "Model: \"sequential_171\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_342 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_343 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 3s 80ms/step - loss: 1.0416 - val_loss: 0.0119\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.0237 - val_loss: 0.0110\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0053 - val_loss: 0.0102\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0049 - val_loss: 0.0094\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.0030 - val_loss: 0.0090\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.0255 - val_loss: 0.0085\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.0126 - val_loss: 0.0081\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0011 - val_loss: 0.0078\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.0069 - val_loss: 0.0072\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9929 - val_loss: 0.0069\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9993 - val_loss: 0.0067\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.0062 - val_loss: 0.0063\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9940 - val_loss: 0.0062\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9902 - val_loss: 0.0060\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9781 - val_loss: 0.0058\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0058 - val_loss: 0.0056\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.9797 - val_loss: 0.0054\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9884 - val_loss: 0.0052\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9818 - val_loss: 0.0051\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.0028 - val_loss: 0.0050\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9830 - val_loss: 0.0049\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9964 - val_loss: 0.0049\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9804 - val_loss: 0.0048\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9911 - val_loss: 0.0048\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0264 - val_loss: 0.0048\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.0039 - val_loss: 0.0048\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9965 - val_loss: 0.0048\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9922 - val_loss: 0.0048\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9970 - val_loss: 0.0047\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9996 - val_loss: 0.0046\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0117 - val_loss: 0.0046\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9828 - val_loss: 0.0046\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9895 - val_loss: 0.0046\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9789 - val_loss: 0.0045\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9978 - val_loss: 0.0044\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9847 - val_loss: 0.0044\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9953 - val_loss: 0.0043\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9815 - val_loss: 0.0043\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9879 - val_loss: 0.0043\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.0184 - val_loss: 0.0042\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9532 - val_loss: 0.0043\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9777 - val_loss: 0.0043\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9666 - val_loss: 0.0043\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9971 - val_loss: 0.0044\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9540 - val_loss: 0.0044\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9823 - val_loss: 0.0045\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9901 - val_loss: 0.0045\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9867 - val_loss: 0.0047\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9415 - val_loss: 0.0049\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9652 - val_loss: 0.0051\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9464 - val_loss: 0.0054\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9386 - val_loss: 0.0058\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9414 - val_loss: 0.0060\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9495 - val_loss: 0.0065\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9341 - val_loss: 0.0068\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.0032\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9761\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0042\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0032\n",
      "X의 형태:  (46, 3, 4)\n",
      "y의 형태:  (46,)\n",
      "X 학습: (32, 3, 4), X 검증: (4, 3, 4), X 평가: (10, 3, 4)\n",
      "y 학습: (32,), y 검증: (4,), y 평가: (10,)\n",
      "Model: \"sequential_172\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_344 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_345 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 2s 63ms/step - loss: 0.9506 - val_loss: 0.4961\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9415 - val_loss: 0.4948\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9021 - val_loss: 0.4935\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8819 - val_loss: 0.4925\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8741 - val_loss: 0.4919\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.8561 - val_loss: 0.4924\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8100 - val_loss: 0.4925\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7868 - val_loss: 0.4934\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7938 - val_loss: 0.4945\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7820 - val_loss: 0.4962\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7822 - val_loss: 0.4987\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7508 - val_loss: 0.5005\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7350 - val_loss: 0.5037\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7316 - val_loss: 0.5045\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7511 - val_loss: 0.5089\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6769 - val_loss: 0.5133\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6849 - val_loss: 0.5185\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5898 - val_loss: 0.5232\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6644 - val_loss: 0.5308\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5704 - val_loss: 0.5380\n",
      "1/1 [==============================] - 1s 990ms/step - loss: 1.8449\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 0.8598\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4919\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.8449\n",
      "X의 형태:  (45, 3, 4)\n",
      "y의 형태:  (45,)\n",
      "X 학습: (31, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (31,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_173\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_346 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_347 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 69ms/step - loss: 0.9829 - val_loss: 0.7987\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9672 - val_loss: 0.7976\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9659 - val_loss: 0.7960\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9533 - val_loss: 0.7947\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9501 - val_loss: 0.7942\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9353 - val_loss: 0.7945\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9087 - val_loss: 0.7948\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9166 - val_loss: 0.7952\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8743 - val_loss: 0.7960\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8852 - val_loss: 0.7969\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8344 - val_loss: 0.7978\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8276 - val_loss: 0.7985\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8152 - val_loss: 0.7993\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.7711 - val_loss: 0.8009\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.7240 - val_loss: 0.8024\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6959 - val_loss: 0.8040\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7410 - val_loss: 0.8071\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6433 - val_loss: 0.8108\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7110 - val_loss: 0.8167\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6298 - val_loss: 0.8245\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 1.9027\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9347\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7942\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.9027\n",
      "X의 형태:  (44, 3, 4)\n",
      "y의 형태:  (44,)\n",
      "X 학습: (30, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_174\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_348 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_349 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 67ms/step - loss: 0.9321 - val_loss: 0.7815\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9212 - val_loss: 0.7813\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9201 - val_loss: 0.7817\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8813 - val_loss: 0.7831\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8814 - val_loss: 0.7851\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8637 - val_loss: 0.7878\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8871 - val_loss: 0.7926\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8366 - val_loss: 0.7985\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8579 - val_loss: 0.8039\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7981 - val_loss: 0.8114\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7533 - val_loss: 0.8200\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.7479 - val_loss: 0.8358\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6704 - val_loss: 0.8498\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6591 - val_loss: 0.8633\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5381 - val_loss: 0.8946\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5742 - val_loss: 0.9157\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6336 - val_loss: 0.9270\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 1.8445\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9226\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7813\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8445\n",
      "X의 형태:  (43, 3, 4)\n",
      "y의 형태:  (43,)\n",
      "X 학습: (30, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_175\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_350 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_351 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 4s 59ms/step - loss: 1.0165 - val_loss: 0.8016\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0147 - val_loss: 0.8066\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0007 - val_loss: 0.8101\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9946 - val_loss: 0.8138\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9909 - val_loss: 0.8166\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9827 - val_loss: 0.8193\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9768 - val_loss: 0.8222\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9696 - val_loss: 0.8245\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9729 - val_loss: 0.8267\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9688 - val_loss: 0.8296\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9489 - val_loss: 0.8318\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9319 - val_loss: 0.8349\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9271 - val_loss: 0.8381\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9377 - val_loss: 0.8429\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8939 - val_loss: 0.8504\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8622 - val_loss: 0.8580\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 1.9113\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0113\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8016\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9113\n",
      "X의 형태:  (42, 3, 4)\n",
      "y의 형태:  (42,)\n",
      "X 학습: (29, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (29,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_176\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_352 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_353 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 65ms/step - loss: 1.0147 - val_loss: 0.8761\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0005 - val_loss: 0.8765\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9968 - val_loss: 0.8785\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9903 - val_loss: 0.8828\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9854 - val_loss: 0.8888\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9768 - val_loss: 0.8963\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9712 - val_loss: 0.9024\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9685 - val_loss: 0.9101\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9700 - val_loss: 0.9175\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9405 - val_loss: 0.9315\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9280 - val_loss: 0.9490\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9286 - val_loss: 0.9718\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9058 - val_loss: 1.0055\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8880 - val_loss: 1.0414\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8870 - val_loss: 1.0887\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8410 - val_loss: 1.1424\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 1.9486\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0076\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8761\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.9486\n",
      "X의 형태:  (41, 3, 4)\n",
      "y의 형태:  (41,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_177\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_354 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_355 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 3s 74ms/step - loss: 1.0362 - val_loss: 0.8950\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0226 - val_loss: 0.9019\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0287 - val_loss: 0.9052\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0099 - val_loss: 0.9115\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0091 - val_loss: 0.9181\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0081 - val_loss: 0.9251\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0098 - val_loss: 0.9332\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9999 - val_loss: 0.9414\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9970 - val_loss: 0.9482\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9916 - val_loss: 0.9532\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9914 - val_loss: 0.9616\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9893 - val_loss: 0.9716\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9849 - val_loss: 0.9789\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9737 - val_loss: 0.9948\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9774 - val_loss: 1.0089\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9638 - val_loss: 1.0252\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 1.9994\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0281\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8950\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.9994\n",
      "X의 형태:  (40, 3, 4)\n",
      "y의 형태:  (40,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (8, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (8,)\n",
      "Model: \"sequential_178\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_356 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_357 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 2s 76ms/step - loss: 0.9956 - val_loss: 1.1141\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.0013 - val_loss: 1.1096\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9871 - val_loss: 1.1076\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9858 - val_loss: 1.1039\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9815 - val_loss: 1.1001\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9918 - val_loss: 1.0976\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9874 - val_loss: 1.0944\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9841 - val_loss: 1.0917\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9897 - val_loss: 1.0887\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9810 - val_loss: 1.0856\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9730 - val_loss: 1.0819\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.9689 - val_loss: 1.0760\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.9634 - val_loss: 1.0714\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9759 - val_loss: 1.0611\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.9688 - val_loss: 1.0505\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9570 - val_loss: 1.0422\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9658 - val_loss: 1.0326\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9503 - val_loss: 1.0254\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9432 - val_loss: 1.0151\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9355 - val_loss: 1.0063\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9409 - val_loss: 0.9999\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9543 - val_loss: 0.9964\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9223 - val_loss: 0.9897\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9547 - val_loss: 0.9817\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.9155 - val_loss: 0.9770\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9118 - val_loss: 0.9823\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8930 - val_loss: 0.9909\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8820 - val_loss: 1.0135\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8735 - val_loss: 1.0746\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8638 - val_loss: 1.1879\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8375 - val_loss: 1.4386\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8163 - val_loss: 1.7470\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8221 - val_loss: 2.1229\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8563 - val_loss: 2.3991\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.8094 - val_loss: 2.2994\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8581 - val_loss: 2.3423\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.7963 - val_loss: 2.4366\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7373 - val_loss: 2.8154\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7733 - val_loss: 3.0859\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8331 - val_loss: 3.3768\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 2.0030\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9043\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9770\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.0030\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['part_number', 'pred_day','train_evaluate', 'val_evaluate', 'test_evaluate', 'mae', 'mse', 'rmse'])\n",
    "\n",
    "for part in [6, 15, 16, 29, 94]:\n",
    "    data = getData(part)\n",
    "    \n",
    "    for num in range(1, 8, 1) :\n",
    "        data_new = getCols(data, num)\n",
    "        \n",
    "        X_list, y_list = getSplitData(data_new, num)\n",
    "        result_list, y_test_part_inv, y_pred_part_inv = getLstmModel(part, num, X_list, y_list)\n",
    "        \n",
    "        df.loc[len(df)] = result_list\n",
    "df.to_csv('./data_new/lstm_결과.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a3782b-774a-4b96-b205-c152f028f708",
   "metadata": {},
   "source": [
    "### 6. 랜덤포레스트 모델 함수(getRFModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c9e6f01b-1b42-401a-8c21-c8e3b4742705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRFModel(part, num, X_list, y_list):\n",
    "    ### 랜덤 포레스트 모델 생성하기\n",
    "    model = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "    \n",
    "    ### 2차원 배열로 변경\n",
    "    X_train = X_list[1].reshape(X_list[1].shape[0], -1)\n",
    "    X_val = X_list[2].reshape(X_list[2].shape[0], -1)\n",
    "    X_test = X_list[3].reshape(X_list[3].shape[0], -1)\n",
    "\n",
    "    ### 모델 훈련시키기\n",
    "    model.fit(X_train, y_list[1])\n",
    "    \n",
    "    ### 테스트 데이터로 성능 평가  \n",
    "    y_pred_part = model.predict(X_test)\n",
    "    \n",
    "    ### 예측값을 기존 값 범위로 역변환\n",
    "    y_pred_part_inv = y_list[0].inverse_transform(y_pred_part.reshape(-1, 1))\n",
    "    y_test_part_inv = y_list[0].inverse_transform(y_list[3])\n",
    "    \n",
    "    ### mae, mse, rmse 계산\n",
    "    mae = mean_absolute_error(y_test_part_inv, y_pred_part_inv)\n",
    "    mse = mean_squared_error(y_test_part_inv, y_pred_part_inv)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    ### 모델 성능 계산\n",
    "    train_eva = model.score(X_train, y_list[1])\n",
    "    val_eva = model.score(X_val, y_list[2])\n",
    "    test_eva = model.score(X_test, y_list[3])\n",
    "    \n",
    "    result_list = [part, num, train_eva, val_eva, test_eva, mae, mse, rmse]\n",
    "    \n",
    "    return result_list, y_test_part_inv, y_pred_part_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b4a4b7-34cd-40f8-a79b-6b20ace5fa3e",
   "metadata": {},
   "source": [
    "### 7. XGBoost 모델 함수(getXGBModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "80ef1dbd-b6c2-475a-88c8-2f46bffd53a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXGBModel(part, num, X_list, y_list):\n",
    "    ### XGBoost 모델 생성하기\n",
    "    model = xgb.XGBRegressor(n_estimators=10, random_state=42)\n",
    "    \n",
    "    ### 2차원 배열로 변경\n",
    "    X_train = X_list[1].reshape(X_list[1].shape[0], -1)\n",
    "    X_val = X_list[2].reshape(X_list[2].shape[0], -1)\n",
    "    X_test = X_list[3].reshape(X_list[3].shape[0], -1)\n",
    "\n",
    "    ### 모델 훈련시키기\n",
    "    model.fit(X_train, y_list[1])\n",
    "    \n",
    "    ### 테스트 데이터로 성능 평가  \n",
    "    y_pred_part = model.predict(X_test)\n",
    "    \n",
    "    ### 예측값을 기존 값 범위로 역변환\n",
    "    y_pred_part_inv = y_list[0].inverse_transform(y_pred_part.reshape(-1, 1))\n",
    "    y_test_part_inv = y_list[0].inverse_transform(y_list[3])\n",
    "    \n",
    "    ### mae, mse, rmse 계산\n",
    "    mae = mean_absolute_error(y_test_part_inv, y_pred_part_inv)\n",
    "    mse = mean_squared_error(y_test_part_inv, y_pred_part_inv)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    ### 모델 성능 계산\n",
    "    train_eva = model.score(X_train, y_list[1])\n",
    "    val_eva = model.score(X_val, y_list[2])\n",
    "    test_eva = model.score(X_test, y_list[3])\n",
    "    \n",
    "    result_list = [part, num, train_eva, val_eva, test_eva, mae, mse, rmse]\n",
    "    \n",
    "    return result_list, y_test_part_inv, y_pred_part_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58df6800-4644-4c97-a5c4-50b1f07beef1",
   "metadata": {},
   "source": [
    "### 8. GradientBoosting 모델 함수(getGBModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ddea7ab6-1fab-49c4-b184-019bcad78c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGBModel(part, num, X_list, y_list):\n",
    "    ### Gradient Boosting 모델 생성하기\n",
    "    model = GradientBoostingRegressor(n_estimators=10, random_state=42)\n",
    "    \n",
    "    ### 2차원 배열로 변경\n",
    "    X_train = X_list[1].reshape(X_list[1].shape[0], -1)\n",
    "    X_val = X_list[2].reshape(X_list[2].shape[0], -1)\n",
    "    X_test = X_list[3].reshape(X_list[3].shape[0], -1)\n",
    "\n",
    "    ### 모델 훈련시키기\n",
    "    model.fit(X_train, y_list[1])\n",
    "    \n",
    "    ### 테스트 데이터로 성능 평가  \n",
    "    y_pred_part = model.predict(X_test)\n",
    "    \n",
    "    ### 예측값을 기존 값 범위로 역변환\n",
    "    y_pred_part_inv = y_list[0].inverse_transform(y_pred_part.reshape(-1, 1))\n",
    "    y_test_part_inv = y_list[0].inverse_transform(y_list[3])\n",
    "    \n",
    "    ### mae, mse, rmse 계산\n",
    "    mae = mean_absolute_error(y_test_part_inv, y_pred_part_inv)\n",
    "    mse = mean_squared_error(y_test_part_inv, y_pred_part_inv)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    ### 모델 성능 계산\n",
    "    train_eva = model.score(X_train, y_list[1])\n",
    "    val_eva = model.score(X_val, y_list[2])\n",
    "    test_eva = model.score(X_test, y_list[3])\n",
    "    \n",
    "    result_list = [part, num, train_eva, val_eva, test_eva, mae, mse, rmse]\n",
    "    \n",
    "    return result_list, y_test_part_inv, y_pred_part_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9b8957-3b89-4844-b29e-f6e5409fa927",
   "metadata": {},
   "source": [
    "### 9. HistGradientBoosting 모델 함수(getHGBModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "724e923e-1aa2-4927-833c-b93d69ae7a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHGBModel(part, num, X_list, y_list):\n",
    "    ### Histogram Gradient Boosting 모델 생성하기\n",
    "    model = HistGradientBoostingRegressor(max_iter=10, random_state=42)\n",
    "    \n",
    "    ### 2차원 배열로 변경\n",
    "    X_train = X_list[1].reshape(X_list[1].shape[0], -1)\n",
    "    X_val = X_list[2].reshape(X_list[2].shape[0], -1)\n",
    "    X_test = X_list[3].reshape(X_list[3].shape[0], -1)\n",
    "\n",
    "    ### 모델 훈련시키기\n",
    "    model.fit(X_train, y_list[1])\n",
    "    \n",
    "    ### 테스트 데이터로 성능 평가  \n",
    "    y_pred_part = model.predict(X_test)\n",
    "    \n",
    "    ### 예측값을 기존 값 범위로 역변환\n",
    "    y_pred_part_inv = y_list[0].inverse_transform(y_pred_part.reshape(-1, 1))\n",
    "    y_test_part_inv = y_list[0].inverse_transform(y_list[3])\n",
    "    \n",
    "    ### mae, mse, rmse 계산\n",
    "    mae = mean_absolute_error(y_test_part_inv, y_pred_part_inv)\n",
    "    mse = mean_squared_error(y_test_part_inv, y_pred_part_inv)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    ### 모델 성능 계산\n",
    "    train_eva = model.score(X_train, y_list[1])\n",
    "    val_eva = model.score(X_val, y_list[2])\n",
    "    test_eva = model.score(X_test, y_list[3])\n",
    "    \n",
    "    result_list = [part, num, train_eva, val_eva, test_eva, mae, mse, rmse]\n",
    "    \n",
    "    return result_list, y_test_part_inv, y_pred_part_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c01239c-6a13-46fd-800c-2ee3df6d8a37",
   "metadata": {},
   "source": [
    "### 함수 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7557f22e-4a4a-42f7-abf2-1fe1a312b306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (46, 3, 4)\n",
      "y의 형태:  (46,)\n",
      "X 학습: (32, 3, 4), X 검증: (4, 3, 4), X 평가: (10, 3, 4)\n",
      "y 학습: (32,), y 검증: (4,), y 평가: (10,)\n",
      "Model: \"sequential_217\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_434 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_435 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 66ms/step - loss: 1.0036 - val_loss: 0.1349\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9982 - val_loss: 0.1357\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9990 - val_loss: 0.1343\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9888 - val_loss: 0.1349\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.9974 - val_loss: 0.1351\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0016 - val_loss: 0.1368\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 1.0014 - val_loss: 0.1359\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.9847 - val_loss: 0.1379\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9879 - val_loss: 0.1381\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.9915 - val_loss: 0.1402\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9845 - val_loss: 0.1420\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9715 - val_loss: 0.1439\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9852 - val_loss: 0.1462\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9834 - val_loss: 0.1516\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9733 - val_loss: 0.1544\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9743 - val_loss: 0.1560\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9769 - val_loss: 0.1590\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9499 - val_loss: 0.1647\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.1148\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 0.9942\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1343\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (45, 3, 4)\n",
      "y의 형태:  (45,)\n",
      "X 학습: (31, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (31,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_218\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_436 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_437 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_218 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 4s 75ms/step - loss: 1.0002 - val_loss: 0.0542\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0035 - val_loss: 0.0574\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0002 - val_loss: 0.0606\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9976 - val_loss: 0.0607\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9942 - val_loss: 0.0612\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9946 - val_loss: 0.0621\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9966 - val_loss: 0.0636\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9889 - val_loss: 0.0643\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9894 - val_loss: 0.0638\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9859 - val_loss: 0.0639\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9851 - val_loss: 0.0641\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9837 - val_loss: 0.0657\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9806 - val_loss: 0.0648\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9940 - val_loss: 0.0643\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9635 - val_loss: 0.0646\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9708 - val_loss: 0.0649\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.0951\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0019\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0542\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0951\n",
      "X의 형태:  (44, 3, 4)\n",
      "y의 형태:  (44,)\n",
      "X 학습: (30, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (5,), y 평가: (9,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_219\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_438 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_439 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_219 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 4s 37ms/step - loss: 1.0094 - val_loss: 0.0677\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.0031 - val_loss: 0.0690\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9978 - val_loss: 0.0673\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9984 - val_loss: 0.0667\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9938 - val_loss: 0.0674\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9889 - val_loss: 0.0665\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9825 - val_loss: 0.0667\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9794 - val_loss: 0.0663\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9860 - val_loss: 0.0666\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9768 - val_loss: 0.0665\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9647 - val_loss: 0.0666\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9730 - val_loss: 0.0659\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9733 - val_loss: 0.0644\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9556 - val_loss: 0.0636\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9587 - val_loss: 0.0629\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9598 - val_loss: 0.0611\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9336 - val_loss: 0.0603\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9339 - val_loss: 0.0572\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9259 - val_loss: 0.0546\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9529 - val_loss: 0.0525\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9285 - val_loss: 0.0508\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9134 - val_loss: 0.0485\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9080 - val_loss: 0.0466\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8926 - val_loss: 0.0440\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9112 - val_loss: 0.0413\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9172 - val_loss: 0.0396\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9065 - val_loss: 0.0381\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9350 - val_loss: 0.0373\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8694 - val_loss: 0.0351\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8962 - val_loss: 0.0332\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8896 - val_loss: 0.0305\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8584 - val_loss: 0.0285\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8968 - val_loss: 0.0264\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8913 - val_loss: 0.0251\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8652 - val_loss: 0.0233\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8764 - val_loss: 0.0215\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8273 - val_loss: 0.0203\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8515 - val_loss: 0.0190\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8192 - val_loss: 0.0178\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8692 - val_loss: 0.0167\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8259 - val_loss: 0.0156\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8572 - val_loss: 0.0148\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8252 - val_loss: 0.0144\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.8325 - val_loss: 0.0136\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8340 - val_loss: 0.0132\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7777 - val_loss: 0.0127\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7424 - val_loss: 0.0124\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8349 - val_loss: 0.0123\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7517 - val_loss: 0.0126\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7322 - val_loss: 0.0128\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7249 - val_loss: 0.0129\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6688 - val_loss: 0.0135\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6795 - val_loss: 0.0134\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7674 - val_loss: 0.0138\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6119 - val_loss: 0.0176\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5535 - val_loss: 0.0206\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5800 - val_loss: 0.0297\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4845 - val_loss: 0.0384\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6176 - val_loss: 0.0386\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2600 - val_loss: 0.0431\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4140 - val_loss: 0.0421\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3423 - val_loss: 0.0749\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3740 - val_loss: 0.0896\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.0651\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7431\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0123\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0651\n",
      "X의 형태:  (43, 3, 4)\n",
      "y의 형태:  (43,)\n",
      "X 학습: (30, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (4,), y 평가: (9,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_220\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_440 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_441 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_220 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 87ms/step - loss: 0.9988 - val_loss: 0.0834\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0006 - val_loss: 0.0823\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9891 - val_loss: 0.0805\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9943 - val_loss: 0.0803\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9798 - val_loss: 0.0809\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9917 - val_loss: 0.0804\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9771 - val_loss: 0.0814\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9938 - val_loss: 0.0797\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9892 - val_loss: 0.0789\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9811 - val_loss: 0.0793\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9714 - val_loss: 0.0794\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9757 - val_loss: 0.0796\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9681 - val_loss: 0.0805\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9708 - val_loss: 0.0819\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9760 - val_loss: 0.0829\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9901 - val_loss: 0.0814\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9693 - val_loss: 0.0818\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9626 - val_loss: 0.0785\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9762 - val_loss: 0.0762\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9591 - val_loss: 0.0743\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9620 - val_loss: 0.0733\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9675 - val_loss: 0.0715\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9655 - val_loss: 0.0705\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9596 - val_loss: 0.0692\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9349 - val_loss: 0.0673\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9576 - val_loss: 0.0651\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9388 - val_loss: 0.0636\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9150 - val_loss: 0.0638\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8983 - val_loss: 0.0584\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9268 - val_loss: 0.0556\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8924 - val_loss: 0.0547\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8829 - val_loss: 0.0544\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8825 - val_loss: 0.0525\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8870 - val_loss: 0.0513\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8759 - val_loss: 0.0503\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8308 - val_loss: 0.0498\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7864 - val_loss: 0.0484\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8685 - val_loss: 0.0460\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8395 - val_loss: 0.0451\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.8111 - val_loss: 0.0457\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8272 - val_loss: 0.0451\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8725 - val_loss: 0.0479\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8449 - val_loss: 0.0523\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.8107 - val_loss: 0.0556\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7729 - val_loss: 0.0547\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.8153 - val_loss: 0.0525\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.8468 - val_loss: 0.0554\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6568 - val_loss: 0.0536\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7487 - val_loss: 0.0525\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5985 - val_loss: 0.0533\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6540 - val_loss: 0.0538\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6013 - val_loss: 0.0575\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5401 - val_loss: 0.0637\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6512 - val_loss: 0.0631\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 0.0878\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8209\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0451\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0878\n",
      "X의 형태:  (42, 3, 4)\n",
      "y의 형태:  (42,)\n",
      "X 학습: (29, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (29,), y 검증: (4,), y 평가: (9,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_221\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_442 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_443 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 91ms/step - loss: 1.0462 - val_loss: 0.0390\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0333 - val_loss: 0.0409\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0128 - val_loss: 0.0429\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0257 - val_loss: 0.0451\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0159 - val_loss: 0.0473\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0000 - val_loss: 0.0502\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.0087 - val_loss: 0.0518\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0028 - val_loss: 0.0529\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0021 - val_loss: 0.0547\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9963 - val_loss: 0.0568\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9942 - val_loss: 0.0588\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9906 - val_loss: 0.0611\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9883 - val_loss: 0.0632\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0007 - val_loss: 0.0650\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9971 - val_loss: 0.0666\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9902 - val_loss: 0.0678\n",
      "1/1 [==============================] - 1s 584ms/step - loss: 0.0645\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0236\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0390\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0645\n",
      "X의 형태:  (41, 3, 4)\n",
      "y의 형태:  (41,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (9,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_222\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_444 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_445 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_222 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 4s 101ms/step - loss: 0.9969 - val_loss: 0.0525\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0098 - val_loss: 0.0533\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.0011 - val_loss: 0.0541\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0115 - val_loss: 0.0551\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9802 - val_loss: 0.0557\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9935 - val_loss: 0.0561\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9834 - val_loss: 0.0575\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9759 - val_loss: 0.0590\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9821 - val_loss: 0.0614\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9937 - val_loss: 0.0631\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9970 - val_loss: 0.0649\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0016 - val_loss: 0.0663\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0003 - val_loss: 0.0670\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0003 - val_loss: 0.0673\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9891 - val_loss: 0.0681\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9795 - val_loss: 0.0699\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 0.0801\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0035\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0525\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0801\n",
      "X의 형태:  (40, 3, 4)\n",
      "y의 형태:  (40,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (8, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (8,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_223\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_446 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_447 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_223 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 4s 105ms/step - loss: 0.9979 - val_loss: 0.0222\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0041 - val_loss: 0.0231\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9950 - val_loss: 0.0237\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9982 - val_loss: 0.0241\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9920 - val_loss: 0.0243\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9910 - val_loss: 0.0247\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9880 - val_loss: 0.0253\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9897 - val_loss: 0.0255\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9954 - val_loss: 0.0262\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9860 - val_loss: 0.0266\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9860 - val_loss: 0.0270\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9951 - val_loss: 0.0277\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9829 - val_loss: 0.0283\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9849 - val_loss: 0.0288\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9842 - val_loss: 0.0293\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9732 - val_loss: 0.0299\n",
      "1/1 [==============================] - 1s 571ms/step - loss: 0.0910\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0004\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0222\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0910\n",
      "X의 형태:  (46, 3, 4)\n",
      "y의 형태:  (46,)\n",
      "X 학습: (32, 3, 4), X 검증: (4, 3, 4), X 평가: (10, 3, 4)\n",
      "y 학습: (32,), y 검증: (4,), y 평가: (10,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_448 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_449 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_224 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 64ms/step - loss: 1.0084 - val_loss: 2.3039\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9984 - val_loss: 2.3188\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9916 - val_loss: 2.3398\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9926 - val_loss: 2.3633\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9943 - val_loss: 2.3941\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.9892 - val_loss: 2.4275\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9878 - val_loss: 2.4554\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9770 - val_loss: 2.4806\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9939 - val_loss: 2.5132\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9822 - val_loss: 2.5320\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9786 - val_loss: 2.5800\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9800 - val_loss: 2.6049\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9688 - val_loss: 2.6459\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9569 - val_loss: 2.7192\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.9449 - val_loss: 2.7701\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9278 - val_loss: 2.8718\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.7342\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 1.0013\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.3039\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7342\n",
      "X의 형태:  (45, 3, 4)\n",
      "y의 형태:  (45,)\n",
      "X 학습: (31, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (31,), y 검증: (5,), y 평가: (9,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_225\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_450 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_451 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 191ms/step - loss: 0.9978 - val_loss: 1.8423\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9945 - val_loss: 1.8467\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9931 - val_loss: 1.8497\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9856 - val_loss: 1.8545\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9924 - val_loss: 1.8588\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9851 - val_loss: 1.8600\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9771 - val_loss: 1.8695\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9803 - val_loss: 1.8767\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9739 - val_loss: 1.8733\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9650 - val_loss: 1.8719\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9457 - val_loss: 1.8741\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9655 - val_loss: 1.8920\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9454 - val_loss: 1.8905\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.9251 - val_loss: 1.8830\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9242 - val_loss: 1.8780\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9156 - val_loss: 1.8815\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.7936\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9969\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8423\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7936\n",
      "X의 형태:  (44, 3, 4)\n",
      "y의 형태:  (44,)\n",
      "X 학습: (30, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (5,), y 평가: (9,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_226\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_452 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_453 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_226 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 87ms/step - loss: 0.9881 - val_loss: 1.9100\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9913 - val_loss: 1.9130\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9908 - val_loss: 1.9066\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9888 - val_loss: 1.9044\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9944 - val_loss: 1.9012\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9946 - val_loss: 1.8991\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9850 - val_loss: 1.9056\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9798 - val_loss: 1.9160\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9797 - val_loss: 1.9184\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9913 - val_loss: 1.9233\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9837 - val_loss: 1.9308\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9864 - val_loss: 1.9376\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9582 - val_loss: 1.9326\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9592 - val_loss: 1.9387\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9467 - val_loss: 1.9419\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9701 - val_loss: 1.9387\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9514 - val_loss: 1.9401\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9373 - val_loss: 1.9469\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9323 - val_loss: 1.9579\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9263 - val_loss: 1.9710\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9316 - val_loss: 1.9935\n",
      "1/1 [==============================] - 1s 585ms/step - loss: 0.6043\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9843\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8991\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6043\n",
      "X의 형태:  (43, 3, 4)\n",
      "y의 형태:  (43,)\n",
      "X 학습: (30, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (4,), y 평가: (9,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_227\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_454 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_455 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 112ms/step - loss: 0.9700 - val_loss: 2.0367\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9715 - val_loss: 2.0393\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9717 - val_loss: 2.0396\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9426 - val_loss: 2.0543\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9732 - val_loss: 2.0634\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9429 - val_loss: 2.0726\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9519 - val_loss: 2.1006\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9489 - val_loss: 2.1079\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9416 - val_loss: 2.1122\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9590 - val_loss: 2.1417\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9358 - val_loss: 2.1470\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9103 - val_loss: 2.1683\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9030 - val_loss: 2.1786\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9454 - val_loss: 2.1944\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9113 - val_loss: 2.2011\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9086 - val_loss: 2.2048\n",
      "1/1 [==============================] - 1s 589ms/step - loss: 0.7915\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9672\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0367\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7915\n",
      "X의 형태:  (42, 3, 4)\n",
      "y의 형태:  (42,)\n",
      "X 학습: (29, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (29,), y 검증: (4,), y 평가: (9,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_228\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_456 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_457 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_228 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 6s 98ms/step - loss: 1.0172 - val_loss: 1.8892\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0124 - val_loss: 1.8922\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9944 - val_loss: 1.8982\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.0114 - val_loss: 1.9040\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0159 - val_loss: 1.9100\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9992 - val_loss: 1.9211\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9955 - val_loss: 1.9265\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0023 - val_loss: 1.9237\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9941 - val_loss: 1.9235\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0010 - val_loss: 1.9232\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9879 - val_loss: 1.9271\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0018 - val_loss: 1.9359\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9914 - val_loss: 1.9428\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9841 - val_loss: 1.9379\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9843 - val_loss: 1.9377\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9885 - val_loss: 1.9398\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 0.7707\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0122\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.8892\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7707\n",
      "X의 형태:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 3, 4)\n",
      "y의 형태:  (41,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_229\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_458 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_459 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 4s 113ms/step - loss: 0.9933 - val_loss: 2.0340\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.0032 - val_loss: 2.0229\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.9914 - val_loss: 2.0204\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9951 - val_loss: 2.0251\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9725 - val_loss: 2.0266\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9772 - val_loss: 2.0281\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9843 - val_loss: 2.0256\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9854 - val_loss: 2.0327\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9648 - val_loss: 2.0397\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9745 - val_loss: 2.0404\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9774 - val_loss: 2.0383\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9802 - val_loss: 2.0414\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9745 - val_loss: 2.0460\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9692 - val_loss: 2.0525\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9506 - val_loss: 2.0615\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9350 - val_loss: 2.0732\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9719 - val_loss: 2.0801\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9499 - val_loss: 2.0838\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 0.5475\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9844\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.0204\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5475\n",
      "X의 형태:  (40, 3, 4)\n",
      "y의 형태:  (40,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (8, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (8,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_230\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_460 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_461 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_230 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 4s 113ms/step - loss: 0.9943 - val_loss: 1.2862\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9964 - val_loss: 1.2844\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0063 - val_loss: 1.2855\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.9960 - val_loss: 1.2841\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.9963 - val_loss: 1.2815\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.9927 - val_loss: 1.2795\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.9971 - val_loss: 1.2785\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.9905 - val_loss: 1.2773\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.9833 - val_loss: 1.2770\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9869 - val_loss: 1.2788\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.9924 - val_loss: 1.2768\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9957 - val_loss: 1.2750\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.9823 - val_loss: 1.2724\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9861 - val_loss: 1.2744\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9882 - val_loss: 1.2741\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9842 - val_loss: 1.2721\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9774 - val_loss: 1.2698\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9782 - val_loss: 1.2707\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9809 - val_loss: 1.2712\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.9795 - val_loss: 1.2681\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.9676 - val_loss: 1.2638\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9842 - val_loss: 1.2605\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9841 - val_loss: 1.2606\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.9636 - val_loss: 1.2563\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9558 - val_loss: 1.2530\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9546 - val_loss: 1.2505\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.9433 - val_loss: 1.2476\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9464 - val_loss: 1.2479\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.9790 - val_loss: 1.2443\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9584 - val_loss: 1.2462\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9559 - val_loss: 1.2539\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9587 - val_loss: 1.2590\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9392 - val_loss: 1.2626\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9328 - val_loss: 1.2690\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9656 - val_loss: 1.2750\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9265 - val_loss: 1.2811\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9643 - val_loss: 1.2873\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9348 - val_loss: 1.2862\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9357 - val_loss: 1.2864\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9386 - val_loss: 1.2864\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9093 - val_loss: 1.2915\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9061 - val_loss: 1.2994\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9362 - val_loss: 1.3031\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9972 - val_loss: 1.3123\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7582\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9496\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2443\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7582\n",
      "X의 형태:  (46, 3, 4)\n",
      "y의 형태:  (46,)\n",
      "X 학습: (32, 3, 4), X 검증: (4, 3, 4), X 평가: (10, 3, 4)\n",
      "y 학습: (32,), y 검증: (4,), y 평가: (10,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_231\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_462 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_463 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 4s 111ms/step - loss: 0.9954 - val_loss: 0.0691\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0003 - val_loss: 0.0680\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9905 - val_loss: 0.0676\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9840 - val_loss: 0.0670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9937 - val_loss: 0.0665\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9877 - val_loss: 0.0656\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9829 - val_loss: 0.0655\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9828 - val_loss: 0.0649\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9716 - val_loss: 0.0649\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9650 - val_loss: 0.0644\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9593 - val_loss: 0.0639\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9735 - val_loss: 0.0639\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9420 - val_loss: 0.0635\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9445 - val_loss: 0.0622\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9210 - val_loss: 0.0608\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9290 - val_loss: 0.0600\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9141 - val_loss: 0.0583\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.8682 - val_loss: 0.0565\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9415 - val_loss: 0.0549\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9026 - val_loss: 0.0520\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.8322 - val_loss: 0.0501\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8669 - val_loss: 0.0504\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.8302 - val_loss: 0.0491\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.8390 - val_loss: 0.0484\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.8374 - val_loss: 0.0451\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8815 - val_loss: 0.0467\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.7820 - val_loss: 0.0482\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8104 - val_loss: 0.0493\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.7792 - val_loss: 0.0498\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9360 - val_loss: 0.0533\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.7860 - val_loss: 0.0630\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.7389 - val_loss: 0.0742\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.8625 - val_loss: 0.0769\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.7208 - val_loss: 0.0776\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.7692 - val_loss: 0.0782\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8154 - val_loss: 0.0792\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.7898 - val_loss: 0.0803\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6698 - val_loss: 0.0842\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.7762 - val_loss: 0.0887\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.7336 - val_loss: 0.0952\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 0.5042\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 0.8044\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0451\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5042\n",
      "X의 형태:  (45, 3, 4)\n",
      "y의 형태:  (45,)\n",
      "X 학습: (31, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (31,), y 검증: (5,), y 평가: (9,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_232\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_464 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_465 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_232 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 6s 112ms/step - loss: 1.0002 - val_loss: 0.0674\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0031 - val_loss: 0.0662\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0035 - val_loss: 0.0643\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0025 - val_loss: 0.0645\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9988 - val_loss: 0.0639\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9959 - val_loss: 0.0635\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0026 - val_loss: 0.0622\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0014 - val_loss: 0.0617\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9879 - val_loss: 0.0619\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9954 - val_loss: 0.0615\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0026 - val_loss: 0.0612\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9949 - val_loss: 0.0600\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9878 - val_loss: 0.0595\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9980 - val_loss: 0.0592\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9899 - val_loss: 0.0587\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9803 - val_loss: 0.0579\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9877 - val_loss: 0.0575\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9971 - val_loss: 0.0564\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9898 - val_loss: 0.0557\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0006 - val_loss: 0.0556\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9978 - val_loss: 0.0552\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9908 - val_loss: 0.0553\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9865 - val_loss: 0.0540\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9790 - val_loss: 0.0528\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9879 - val_loss: 0.0523\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9690 - val_loss: 0.0510\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9849 - val_loss: 0.0492\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9933 - val_loss: 0.0482\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9765 - val_loss: 0.0464\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9800 - val_loss: 0.0462\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9822 - val_loss: 0.0442\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9653 - val_loss: 0.0433\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9727 - val_loss: 0.0403\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9683 - val_loss: 0.0385\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9761 - val_loss: 0.0372\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9642 - val_loss: 0.0347\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9671 - val_loss: 0.0332\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9601 - val_loss: 0.0306\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9381 - val_loss: 0.0278\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9448 - val_loss: 0.0252\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9560 - val_loss: 0.0227\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9425 - val_loss: 0.0203\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9153 - val_loss: 0.0174\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9087 - val_loss: 0.0167\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.8927 - val_loss: 0.0157\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.8557 - val_loss: 0.0112\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.8913 - val_loss: 0.0081\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.8183 - val_loss: 0.0059\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.8877 - val_loss: 0.0033\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.8431 - val_loss: 0.0026\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7958 - val_loss: 0.0024\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.8104 - val_loss: 0.0023\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7848 - val_loss: 0.0027\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7063 - val_loss: 0.0026\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9227 - val_loss: 0.0041\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8405 - val_loss: 0.0041\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7866 - val_loss: 0.0064\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.7654 - val_loss: 0.0103\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8540 - val_loss: 0.0025\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8080 - val_loss: 0.0023\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7412 - val_loss: 0.0026\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7393 - val_loss: 0.0039\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7218 - val_loss: 0.0029\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.7230 - val_loss: 0.0026\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.7164 - val_loss: 0.0028\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7573 - val_loss: 0.0046\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7738 - val_loss: 0.0034\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.5897\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8039\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0023\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5897\n",
      "X의 형태:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 3, 4)\n",
      "y의 형태:  (44,)\n",
      "X 학습: (30, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_233\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_466 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_467 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 7s 122ms/step - loss: 1.0055 - val_loss: 0.0607\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9939 - val_loss: 0.0600\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9875 - val_loss: 0.0612\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9849 - val_loss: 0.0620\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9859 - val_loss: 0.0624\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9832 - val_loss: 0.0631\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9602 - val_loss: 0.0631\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9584 - val_loss: 0.0641\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9772 - val_loss: 0.0641\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9554 - val_loss: 0.0646\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9325 - val_loss: 0.0652\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9457 - val_loss: 0.0645\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9566 - val_loss: 0.0641\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9391 - val_loss: 0.0639\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9669 - val_loss: 0.0652\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9153 - val_loss: 0.0672\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9266 - val_loss: 0.0665\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 0.7791\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9819\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0600\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7791\n",
      "X의 형태:  (43, 3, 4)\n",
      "y의 형태:  (43,)\n",
      "X 학습: (30, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (4,), y 평가: (9,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_234\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_468 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_469 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_234 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 8s 148ms/step - loss: 0.9889 - val_loss: 0.0646\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9880 - val_loss: 0.0654\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9864 - val_loss: 0.0667\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9792 - val_loss: 0.0670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9928 - val_loss: 0.0672\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9782 - val_loss: 0.0673\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9741 - val_loss: 0.0661\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9622 - val_loss: 0.0672\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9673 - val_loss: 0.0682\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9680 - val_loss: 0.0680\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9544 - val_loss: 0.0689\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9790 - val_loss: 0.0684\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9536 - val_loss: 0.0685\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9510 - val_loss: 0.0697\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9731 - val_loss: 0.0704\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9692 - val_loss: 0.0721\n",
      "1/1 [==============================] - 1s 923ms/step - loss: 0.7246\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9810\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0646\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (42, 3, 4)\n",
      "y의 형태:  (42,)\n",
      "X 학습: (29, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (29,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_235\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_470 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_471 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_235 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 7s 136ms/step - loss: 0.9944 - val_loss: 0.0459\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0018 - val_loss: 0.0483\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.9839 - val_loss: 0.0498\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9965 - val_loss: 0.0505\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9865 - val_loss: 0.0525\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9804 - val_loss: 0.0527\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9938 - val_loss: 0.0538\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9728 - val_loss: 0.0549\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9879 - val_loss: 0.0568\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9760 - val_loss: 0.0599\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9768 - val_loss: 0.0621\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9688 - val_loss: 0.0636\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9860 - val_loss: 0.0652\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9700 - val_loss: 0.0685\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9637 - val_loss: 0.0727\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9520 - val_loss: 0.0737\n",
      "1/1 [==============================] - 1s 967ms/step - loss: 0.6403\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9961\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0459\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (41, 3, 4)\n",
      "y의 형태:  (41,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_236\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_472 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_473 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_236 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 7s 169ms/step - loss: 1.0107 - val_loss: 0.0314\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.0202 - val_loss: 0.0349\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9954 - val_loss: 0.0368\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.0090 - val_loss: 0.0369\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9775 - val_loss: 0.0383\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 1.0032 - val_loss: 0.0396\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9987 - val_loss: 0.0415\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9925 - val_loss: 0.0432\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9898 - val_loss: 0.0430\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9902 - val_loss: 0.0442\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9773 - val_loss: 0.0465\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9977 - val_loss: 0.0474\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9870 - val_loss: 0.0507\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9764 - val_loss: 0.0505\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9851 - val_loss: 0.0525\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9783 - val_loss: 0.0526\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5895\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0101\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0314\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (40, 3, 4)\n",
      "y의 형태:  (40,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (8, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (8,)\n",
      "Model: \"sequential_237\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_474 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_475 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 6s 150ms/step - loss: 1.0029 - val_loss: 0.0137\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9938 - val_loss: 0.0152\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9984 - val_loss: 0.0168\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9848 - val_loss: 0.0177\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9853 - val_loss: 0.0199\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9780 - val_loss: 0.0214\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9732 - val_loss: 0.0229\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9551 - val_loss: 0.0247\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9607 - val_loss: 0.0257\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9624 - val_loss: 0.0276\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9549 - val_loss: 0.0296\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9392 - val_loss: 0.0300\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9412 - val_loss: 0.0315\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9264 - val_loss: 0.0317\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9412 - val_loss: 0.0326\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9152 - val_loss: 0.0322\n",
      "1/1 [==============================] - 1s 945ms/step - loss: 0.5732\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9975\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0137\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (46, 3, 4)\n",
      "y의 형태:  (46,)\n",
      "X 학습: (32, 3, 4), X 검증: (4, 3, 4), X 평가: (10, 3, 4)\n",
      "y 학습: (32,), y 검증: (4,), y 평가: (10,)\n",
      "Model: \"sequential_238\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_476 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_477 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_238 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 6s 153ms/step - loss: 1.0102 - val_loss: 0.0399\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0005 - val_loss: 0.0361\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9988 - val_loss: 0.0333\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0125 - val_loss: 0.0307\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9808 - val_loss: 0.0285\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9805 - val_loss: 0.0260\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9801 - val_loss: 0.0239\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9762 - val_loss: 0.0214\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9563 - val_loss: 0.0190\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9510 - val_loss: 0.0159\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9549 - val_loss: 0.0127\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9118 - val_loss: 0.0101\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9189 - val_loss: 0.0075\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.8976 - val_loss: 0.0054\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8952 - val_loss: 0.0055\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9169 - val_loss: 0.0061\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9039 - val_loss: 0.0068\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8520 - val_loss: 0.0076\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8826 - val_loss: 0.0087\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8913 - val_loss: 0.0104\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9165 - val_loss: 0.0082\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8959 - val_loss: 0.0082\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8640 - val_loss: 0.0085\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8814 - val_loss: 0.0089\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8755 - val_loss: 0.0088\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9036 - val_loss: 0.0092\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8581 - val_loss: 0.0098\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8624 - val_loss: 0.0102\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8840 - val_loss: 0.0104\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.0060\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.8878\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0054\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (45, 3, 4)\n",
      "y의 형태:  (45,)\n",
      "X 학습: (31, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (31,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_239\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_478 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_479 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 9s 164ms/step - loss: 0.9957 - val_loss: 0.0292\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0035 - val_loss: 0.0271\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9963 - val_loss: 0.0242\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9962 - val_loss: 0.0232\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9927 - val_loss: 0.0218\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9946 - val_loss: 0.0203\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9943 - val_loss: 0.0181\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.9745 - val_loss: 0.0165\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9668 - val_loss: 0.0152\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9776 - val_loss: 0.0136\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9612 - val_loss: 0.0114\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9650 - val_loss: 0.0082\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9457 - val_loss: 0.0061\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9695 - val_loss: 0.0048\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9443 - val_loss: 0.0041\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9266 - val_loss: 0.0046\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9376 - val_loss: 0.0063\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9405 - val_loss: 0.0109\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.8914 - val_loss: 0.0140\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9137 - val_loss: 0.0175\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9244 - val_loss: 0.0242\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9362 - val_loss: 0.0281\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8862 - val_loss: 0.0223\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8858 - val_loss: 0.0216\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9201 - val_loss: 0.0231\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8892 - val_loss: 0.0240\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.8825 - val_loss: 0.0187\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8989 - val_loss: 0.0168\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8869 - val_loss: 0.0184\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.8674 - val_loss: 0.0189\n",
      "1/1 [==============================] - 1s 1000ms/step - loss: 0.0072\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9360\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0041\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (44, 3, 4)\n",
      "y의 형태:  (44,)\n",
      "X 학습: (30, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_240\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_480 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_481 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_240 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 9s 168ms/step - loss: 0.9928 - val_loss: 0.0129\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.9951 - val_loss: 0.0122\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.9814 - val_loss: 0.0122\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9816 - val_loss: 0.0117\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.9748 - val_loss: 0.0109\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9691 - val_loss: 0.0100\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9802 - val_loss: 0.0089\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9582 - val_loss: 0.0083\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9650 - val_loss: 0.0074\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9681 - val_loss: 0.0066\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.9615 - val_loss: 0.0060\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.9637 - val_loss: 0.0055\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.9517 - val_loss: 0.0054\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9460 - val_loss: 0.0055\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9539 - val_loss: 0.0058\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9613 - val_loss: 0.0063\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9469 - val_loss: 0.0065\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9448 - val_loss: 0.0059\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9312 - val_loss: 0.0059\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9510 - val_loss: 0.0060\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9222 - val_loss: 0.0060\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.9463 - val_loss: 0.0061\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9517 - val_loss: 0.0062\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9423 - val_loss: 0.0063\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9439 - val_loss: 0.0064\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9347 - val_loss: 0.0065\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9318 - val_loss: 0.0068\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9365 - val_loss: 0.0075\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0069\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.9467\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0054\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (43, 3, 4)\n",
      "y의 형태:  (43,)\n",
      "X 학습: (30, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_241\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_482 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_483 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 9s 130ms/step - loss: 1.0025 - val_loss: 0.0226\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9962 - val_loss: 0.0224\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9968 - val_loss: 0.0222\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0030 - val_loss: 0.0211\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9834 - val_loss: 0.0203\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9947 - val_loss: 0.0194\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9897 - val_loss: 0.0179\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9842 - val_loss: 0.0177\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9857 - val_loss: 0.0172\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.9793 - val_loss: 0.0158\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9811 - val_loss: 0.0149\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9771 - val_loss: 0.0131\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9671 - val_loss: 0.0114\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9733 - val_loss: 0.0097\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9706 - val_loss: 0.0080\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9725 - val_loss: 0.0069\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9485 - val_loss: 0.0056\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9475 - val_loss: 0.0051\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9417 - val_loss: 0.0047\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9283 - val_loss: 0.0052\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9586 - val_loss: 0.0074\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9405 - val_loss: 0.0107\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9009 - val_loss: 0.0131\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9035 - val_loss: 0.0128\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8955 - val_loss: 0.0101\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9407 - val_loss: 0.0087\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9182 - val_loss: 0.0087\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8762 - val_loss: 0.0085\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9548 - val_loss: 0.0075\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9284 - val_loss: 0.0099\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8653 - val_loss: 0.0128\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9082 - val_loss: 0.0158\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9144 - val_loss: 0.0137\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8844 - val_loss: 0.0108\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.0055\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9396\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0047\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (42, 3, 4)\n",
      "y의 형태:  (42,)\n",
      "X 학습: (29, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (29,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_242\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_484 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_485 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_242 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 7s 128ms/step - loss: 1.0415 - val_loss: 0.0341\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0381 - val_loss: 0.0309\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0091 - val_loss: 0.0282\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0294 - val_loss: 0.0256\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0203 - val_loss: 0.0237\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0111 - val_loss: 0.0206\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0191 - val_loss: 0.0183\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0097 - val_loss: 0.0171\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0138 - val_loss: 0.0164\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9969 - val_loss: 0.0163\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0028 - val_loss: 0.0157\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0039 - val_loss: 0.0147\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9918 - val_loss: 0.0140\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9953 - val_loss: 0.0139\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9958 - val_loss: 0.0138\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9896 - val_loss: 0.0131\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0051 - val_loss: 0.0123\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9819 - val_loss: 0.0121\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9829 - val_loss: 0.0121\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9855 - val_loss: 0.0125\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9935 - val_loss: 0.0129\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9809 - val_loss: 0.0129\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9759 - val_loss: 0.0121\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9794 - val_loss: 0.0119\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9858 - val_loss: 0.0112\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9826 - val_loss: 0.0112\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.9838 - val_loss: 0.0109\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9626 - val_loss: 0.0093\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9793 - val_loss: 0.0093\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9678 - val_loss: 0.0088\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9577 - val_loss: 0.0086\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9551 - val_loss: 0.0084\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.9531 - val_loss: 0.0081\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9598 - val_loss: 0.0081\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9638 - val_loss: 0.0081\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9433 - val_loss: 0.0083\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9543 - val_loss: 0.0086\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9498 - val_loss: 0.0088\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9654 - val_loss: 0.0086\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9692 - val_loss: 0.0086\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9642 - val_loss: 0.0088\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9523 - val_loss: 0.0090\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9427 - val_loss: 0.0090\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9426 - val_loss: 0.0092\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9838 - val_loss: 0.0096\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9302 - val_loss: 0.0094\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9282 - val_loss: 0.0104\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9352 - val_loss: 0.0115\n",
      "1/1 [==============================] - 1s 757ms/step - loss: 0.0041\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9544\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0081\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (41, 3, 4)\n",
      "y의 형태:  (41,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_243\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_486 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_487 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_243 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 6s 155ms/step - loss: 0.9943 - val_loss: 0.0072\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.9707 - val_loss: 0.0069\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.9867 - val_loss: 0.0066\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.9521 - val_loss: 0.0063\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.9539 - val_loss: 0.0063\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9978 - val_loss: 0.0064\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9670 - val_loss: 0.0066\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9689 - val_loss: 0.0071\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9452 - val_loss: 0.0081\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9534 - val_loss: 0.0092\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9533 - val_loss: 0.0103\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9298 - val_loss: 0.0121\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9354 - val_loss: 0.0135\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9291 - val_loss: 0.0158\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9541 - val_loss: 0.0157\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9024 - val_loss: 0.0173\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9308 - val_loss: 0.0174\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.8776 - val_loss: 0.0167\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9189 - val_loss: 0.0156\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9060 - val_loss: 0.0147\n",
      "1/1 [==============================] - 1s 896ms/step - loss: 0.0044\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9614\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0063\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (40, 3, 4)\n",
      "y의 형태:  (40,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (8, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (8,)\n",
      "Model: \"sequential_244\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_488 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_489 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_244 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 7s 171ms/step - loss: 1.0026 - val_loss: 0.0071\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.0103 - val_loss: 0.0073\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.0045 - val_loss: 0.0073\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 1.0015 - val_loss: 0.0073\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.0050 - val_loss: 0.0075\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.0045 - val_loss: 0.0074\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0013 - val_loss: 0.0074\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 1.0028 - val_loss: 0.0073\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.9941 - val_loss: 0.0070\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.9961 - val_loss: 0.0069\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.9962 - val_loss: 0.0068\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 1.0001 - val_loss: 0.0065\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.9951 - val_loss: 0.0065\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.9925 - val_loss: 0.0063\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.9949 - val_loss: 0.0061\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.9946 - val_loss: 0.0058\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.9970 - val_loss: 0.0056\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.9902 - val_loss: 0.0054\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.9886 - val_loss: 0.0052\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.9864 - val_loss: 0.0051\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.9832 - val_loss: 0.0050\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.9998 - val_loss: 0.0049\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9872 - val_loss: 0.0050\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.9870 - val_loss: 0.0050\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.9895 - val_loss: 0.0049\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.9853 - val_loss: 0.0048\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.9849 - val_loss: 0.0047\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.9799 - val_loss: 0.0046\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.9843 - val_loss: 0.0045\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.9813 - val_loss: 0.0044\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.9840 - val_loss: 0.0043\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.9818 - val_loss: 0.0043\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.9629 - val_loss: 0.0042\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.9792 - val_loss: 0.0043\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9635 - val_loss: 0.0046\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9719 - val_loss: 0.0048\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9661 - val_loss: 0.0050\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.9660 - val_loss: 0.0050\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9622 - val_loss: 0.0054\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9666 - val_loss: 0.0057\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9556 - val_loss: 0.0065\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9549 - val_loss: 0.0064\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9502 - val_loss: 0.0058\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.9564 - val_loss: 0.0058\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9552 - val_loss: 0.0061\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9667 - val_loss: 0.0063\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9674 - val_loss: 0.0062\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9531 - val_loss: 0.0055\n",
      "1/1 [==============================] - 1s 892ms/step - loss: 0.0042\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9697\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0042\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (46, 3, 4)\n",
      "y의 형태:  (46,)\n",
      "X 학습: (32, 3, 4), X 검증: (4, 3, 4), X 평가: (10, 3, 4)\n",
      "y 학습: (32,), y 검증: (4,), y 평가: (10,)\n",
      "Model: \"sequential_245\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_490 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_491 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_245 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 6s 157ms/step - loss: 0.9366 - val_loss: 0.4894\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9281 - val_loss: 0.4856\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9101 - val_loss: 0.4870\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9098 - val_loss: 0.4865\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9010 - val_loss: 0.4856\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8903 - val_loss: 0.4885\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8622 - val_loss: 0.4917\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8299 - val_loss: 0.5024\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8613 - val_loss: 0.5117\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8702 - val_loss: 0.5235\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7751 - val_loss: 0.5405\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7705 - val_loss: 0.5516\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7407 - val_loss: 0.5548\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7372 - val_loss: 0.5495\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7590 - val_loss: 0.5635\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7582 - val_loss: 0.5624\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7114 - val_loss: 0.5509\n",
      "1/1 [==============================] - 1s 880ms/step - loss: 1.7425\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 0.9246\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4856\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.7425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (45, 3, 4)\n",
      "y의 형태:  (45,)\n",
      "X 학습: (31, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (31,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_246\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_492 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_493 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_246 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 8s 148ms/step - loss: 0.9987 - val_loss: 0.7903\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9972 - val_loss: 0.7907\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9930 - val_loss: 0.7906\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9888 - val_loss: 0.7904\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9861 - val_loss: 0.7902\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9815 - val_loss: 0.7898\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9730 - val_loss: 0.7890\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.9727 - val_loss: 0.7882\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9555 - val_loss: 0.7880\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9448 - val_loss: 0.7883\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.9306 - val_loss: 0.7879\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.9239 - val_loss: 0.7876\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8894 - val_loss: 0.7869\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8652 - val_loss: 0.7868\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.8462 - val_loss: 0.7867\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7910 - val_loss: 0.7851\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7945 - val_loss: 0.7843\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7146 - val_loss: 0.7835\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.7487 - val_loss: 0.7829\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7178 - val_loss: 0.7832\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.6789 - val_loss: 0.7838\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6270 - val_loss: 0.7860\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.6887 - val_loss: 0.7903\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.6620 - val_loss: 0.7927\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5868 - val_loss: 0.7947\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5448 - val_loss: 0.7972\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6217 - val_loss: 0.8040\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5353 - val_loss: 0.8099\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6112 - val_loss: 0.8193\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5852 - val_loss: 0.8252\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5435 - val_loss: 0.8247\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5792 - val_loss: 0.8278\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5417 - val_loss: 0.8307\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5231 - val_loss: 0.8227\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 1.6651\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6620\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7829\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.6651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (44, 3, 4)\n",
      "y의 형태:  (44,)\n",
      "X 학습: (30, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_247\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_494 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_495 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_247 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 6s 110ms/step - loss: 0.9456 - val_loss: 0.7951\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9425 - val_loss: 0.7962\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9229 - val_loss: 0.7977\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9120 - val_loss: 0.7993\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9158 - val_loss: 0.8017\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8703 - val_loss: 0.8051\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8402 - val_loss: 0.8096\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8396 - val_loss: 0.8170\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8115 - val_loss: 0.8257\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7740 - val_loss: 0.8359\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6923 - val_loss: 0.8472\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.7224 - val_loss: 0.8674\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6086 - val_loss: 0.8891\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6239 - val_loss: 0.9166\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5672 - val_loss: 0.9568\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6078 - val_loss: 0.9886\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 1.9004\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9401\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7951\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.9004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (43, 3, 4)\n",
      "y의 형태:  (43,)\n",
      "X 학습: (30, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_248\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_496 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_497 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_248 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 7s 139ms/step - loss: 1.0002 - val_loss: 0.8862\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9704 - val_loss: 0.9026\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9726 - val_loss: 0.9179\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9619 - val_loss: 0.9374\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9582 - val_loss: 0.9579\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9368 - val_loss: 0.9800\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9197 - val_loss: 1.0117\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9049 - val_loss: 1.0471\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8958 - val_loss: 1.0837\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8486 - val_loss: 1.1409\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8055 - val_loss: 1.1975\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7978 - val_loss: 1.2868\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7293 - val_loss: 1.3947\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7419 - val_loss: 1.5154\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7054 - val_loss: 1.6983\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7408 - val_loss: 1.8352\n",
      "1/1 [==============================] - 1s 811ms/step - loss: 1.9736\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9910\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8862\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.9736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (42, 3, 4)\n",
      "y의 형태:  (42,)\n",
      "X 학습: (29, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (29,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_249\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_498 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_499 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_249 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 8s 133ms/step - loss: 0.9897 - val_loss: 0.9415\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9770 - val_loss: 0.9468\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9744 - val_loss: 0.9554\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9658 - val_loss: 0.9653\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9554 - val_loss: 0.9772\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9357 - val_loss: 0.9963\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9248 - val_loss: 1.0119\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9460 - val_loss: 1.0299\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9305 - val_loss: 1.0450\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9009 - val_loss: 1.0656\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8670 - val_loss: 1.0903\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8639 - val_loss: 1.1209\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8213 - val_loss: 1.1778\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8223 - val_loss: 1.2358\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8220 - val_loss: 1.3070\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7498 - val_loss: 1.3874\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 1.9305\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9841\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9415\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.9305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (41, 3, 4)\n",
      "y의 형태:  (41,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_250\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_500 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_501 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_250 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 5s 155ms/step - loss: 1.0089 - val_loss: 0.9045\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9907 - val_loss: 0.9107\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9913 - val_loss: 0.9148\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9881 - val_loss: 0.9212\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9794 - val_loss: 0.9285\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9770 - val_loss: 0.9368\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.9722 - val_loss: 0.9439\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9536 - val_loss: 0.9531\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9614 - val_loss: 0.9632\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9535 - val_loss: 0.9721\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9317 - val_loss: 0.9870\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9190 - val_loss: 1.0036\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9298 - val_loss: 1.0140\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.9109 - val_loss: 1.0328\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.8625 - val_loss: 1.0586\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.8648 - val_loss: 1.0949\n",
      "1/1 [==============================] - 1s 759ms/step - loss: 1.9255\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0006\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9045\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.9255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (40, 3, 4)\n",
      "y의 형태:  (40,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (8, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (8,)\n",
      "Model: \"sequential_251\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_502 (LSTM)             (None, 3, 8)              416       \n",
      "                                                                 \n",
      " lstm_503 (LSTM)             (None, 8)                 544       \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969\n",
      "Trainable params: 969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 5s 137ms/step - loss: 1.0393 - val_loss: 1.1933\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.0463 - val_loss: 1.1823\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.0260 - val_loss: 1.1758\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.0233 - val_loss: 1.1680\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.0225 - val_loss: 1.1613\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.0265 - val_loss: 1.1564\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.0309 - val_loss: 1.1508\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.0178 - val_loss: 1.1465\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.0062 - val_loss: 1.1422\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.0137 - val_loss: 1.1388\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.0085 - val_loss: 1.1351\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.0118 - val_loss: 1.1307\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.0142 - val_loss: 1.1278\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.0030 - val_loss: 1.1218\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.9966 - val_loss: 1.1154\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.9949 - val_loss: 1.1096\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.9932 - val_loss: 1.1031\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.0001 - val_loss: 1.1000\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.9972 - val_loss: 1.0942\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.9912 - val_loss: 1.0910\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.9815 - val_loss: 1.0856\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.9896 - val_loss: 1.0786\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.9920 - val_loss: 1.0721\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.9868 - val_loss: 1.0639\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.9712 - val_loss: 1.0560\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.9786 - val_loss: 1.0477\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.9593 - val_loss: 1.0395\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.9744 - val_loss: 1.0269\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.9749 - val_loss: 1.0184\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.9560 - val_loss: 1.0117\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.9519 - val_loss: 0.9967\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.9464 - val_loss: 0.9820\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.9409 - val_loss: 0.9658\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.9606 - val_loss: 0.9562\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.9254 - val_loss: 0.9450\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.8958 - val_loss: 0.9380\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.9261 - val_loss: 0.9286\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.8601 - val_loss: 0.9218\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.9344 - val_loss: 0.9161\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.9060 - val_loss: 0.9053\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.8433 - val_loss: 0.9049\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.8040 - val_loss: 0.9108\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.8595 - val_loss: 0.9362\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.7761 - val_loss: 0.9756\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.8231 - val_loss: 1.0428\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7702 - val_loss: 1.1308\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.8724 - val_loss: 1.2838\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7791 - val_loss: 1.4377\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6992 - val_loss: 1.5968\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6363 - val_loss: 1.9048\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6834 - val_loss: 2.4393\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7384 - val_loss: 2.9895\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7294 - val_loss: 3.3147\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7481 - val_loss: 3.5707\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.7479 - val_loss: 3.3485\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.7104 - val_loss: 2.9240\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 1.8916\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8418\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9049\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.8916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\siyoon\\anaconda3\\envs\\project\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# 각 모델의 결과를 저장할 데이터프레임 생성\n",
    "models = ['LSTM', 'RF', 'XGB', 'GB', 'HGB']\n",
    "dfs = {model: pd.DataFrame(columns=['part_number', 'pred_day', 'train_evaluate', 'val_evaluate', 'test_evaluate', 'mae', 'mse', 'rmse']) for model in models}\n",
    "\n",
    "# 분석할 부품(part) 리스트\n",
    "parts = [6, 15, 16, 29, 94]\n",
    "\n",
    "# 각 부품에 대해 반복\n",
    "for part in parts:\n",
    "    data = getData(part)\n",
    "    \n",
    "    # 1부터 7까지의 범위로 반복\n",
    "    for num in range(1, 8, 1):\n",
    "        data_new = getCols(data, num)\n",
    "        \n",
    "        X_list, y_list = getSplitData(data_new, num)\n",
    "        \n",
    "        # 각 모델에 대한 결과를 얻어서 해당 데이터프레임에 추가\n",
    "        for model in models:\n",
    "            result_list, _, _ = globals()[f'get{model}Model'](part, num, X_list, y_list)\n",
    "            dfs[model].loc[len(dfs[model])] = result_list\n",
    "\n",
    "# 결과를 각 모델에 대한 CSV 파일로 저장\n",
    "for model in models:\n",
    "    dfs[model].to_csv(f'./data_new/{model.lower()}_결과.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035c1c0a-a3a9-4146-af7f-5b77a47e1fff",
   "metadata": {},
   "source": [
    "## 각 모델 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "557bd48e-4789-42f5-a32b-dbe7b4f97227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lstm</th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>gb</th>\n",
       "      <th>hgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.874576</td>\n",
       "      <td>12.817189</td>\n",
       "      <td>12.883608</td>\n",
       "      <td>12.270567</td>\n",
       "      <td>9.435244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.446987</td>\n",
       "      <td>10.150671</td>\n",
       "      <td>14.300918</td>\n",
       "      <td>10.865720</td>\n",
       "      <td>9.596393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.963830</td>\n",
       "      <td>18.331679</td>\n",
       "      <td>19.382355</td>\n",
       "      <td>17.576702</td>\n",
       "      <td>16.641397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.741370</td>\n",
       "      <td>17.067289</td>\n",
       "      <td>40.694170</td>\n",
       "      <td>13.159314</td>\n",
       "      <td>15.048942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.102161</td>\n",
       "      <td>7.227756</td>\n",
       "      <td>6.590934</td>\n",
       "      <td>6.758569</td>\n",
       "      <td>6.245571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lstm         rf        xgb         gb        hgb\n",
       "0   8.874576  12.817189  12.883608  12.270567   9.435244\n",
       "1   9.446987  10.150671  14.300918  10.865720   9.596393\n",
       "2  15.963830  18.331679  19.382355  17.576702  16.641397\n",
       "3   9.741370  17.067289  40.694170  13.159314  15.048942\n",
       "4   6.102161   7.227756   6.590934   6.758569   6.245571"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5개의 모델 리스트\n",
    "models = ['lstm', 'rf', 'xgb', 'gb', 'hgb']\n",
    "# 모든 결과를 저장할 데이터프레임\n",
    "final_rmse_df = pd.DataFrame()\n",
    "\n",
    "# 각 모델에 대해 작업 수행\n",
    "for model in models:\n",
    "    # 모델 결과 데이터 로드\n",
    "    df = pd.read_csv(f\"./data_new/{model}_결과.csv\")\n",
    "    # part_number 기준으로 rmse의 평균을 계산\n",
    "    result_df = df.groupby('part_number')['rmse'].mean().reset_index()\n",
    "    # 결과 데이터프레임에 열 방향으로 합치기\n",
    "    final_rmse_df = pd.concat([final_rmse_df, result_df['rmse']], axis=1, ignore_index=True)\n",
    "\n",
    "# 각 모델명을 컬럼명으로 설정\n",
    "final_rmse_df.columns = models\n",
    "\n",
    "# 저장하기\n",
    "final_rmse_df.to_csv('./data_new/모델별_rmse_평균.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 최종 결과 출력\n",
    "final_rmse_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b8fd4b-0c6e-4d1a-9541-6192cb116b88",
   "metadata": {},
   "source": [
    "lstm과 앙상블 모델을 학습 후 rmse를 기준으로 비교함<br>\n",
    "각 부품 넘버별 D+1~7의 평균 rmse를 비교하기로 함<br><br>\n",
    "\n",
    "비교 결과, 모든 부품에서 lstm의 rmse 평균이 가장 낮음<br>\n",
    "따라서, lstm 모델이 가장 적합한 모델이라 판단하여 최종 모델로 선정함<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4498cf60-9af7-4f4d-bcab-ca77c7e6a2ed",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6846dd0-20a8-4db2-81b7-5f9e944de023",
   "metadata": {},
   "source": [
    "## LSTM 모델 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6810a3a1-9dad-4e61-a1e3-2151e698da64",
   "metadata": {},
   "source": [
    "### LSTM 모델 튜닝 함수(getLSTMTuningModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42de07bf-5300-4691-b694-d5a83b665f07",
   "metadata": {},
   "source": [
    "LSTM 모델의 loss가 높게 나와 손실 가중치를 주어 loss를 줄이고자 함. loss_weights=0.01로 주고 실행<br>\n",
    "그 외의 하이퍼파라미터 튜닝은 아래와 같이 실험을 해봄\n",
    "\n",
    "1. LSTM 뉴런 수 조정 (8, 16, 32, 64) : 32 선정\n",
    "2. Dropout 조정 (->0.1~0.5) : 0.2 선정\n",
    "3. 활성화 함수 변경 (relu, leaky_relu) : leaky_relu 선정\n",
    "4. 옵티마이저 변경 (adam, sgd) : adam 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6ecb89de-99cc-4fc9-880a-54b728ee05b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLSTMTuningModel(part, num, X_list, y_list) :\n",
    "    ### 신경망 모델 생성하기\n",
    "    model = Sequential()\n",
    "    \n",
    "    ### LSTM 계층 추가하기\n",
    "    model.add(LSTM(32, dropout=0.2, activation='leaky_relu', input_shape=(3, 4), return_sequences=True))\n",
    "    model.add(LSTM(32, dropout=0.2, activation='leaky_relu'))\n",
    "    \n",
    "    ### 출력 계층 추가하기\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    ### 모델 상태 확인하기\n",
    "    model.summary()\n",
    "    \n",
    "    ### 모델 설정하기\n",
    "    model.compile(optimizer='adam', loss='mse', loss_weights=0.01)\n",
    "    \n",
    "    ### 모델 저장 경로 지정\n",
    "    model_path = './models/part{}_d{}_lstm_tuning.h5'.format(part, num)\n",
    "\n",
    "    ### 콜백 함수 지정\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=15),\n",
    "                ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=0, save_best_only=True)]\n",
    "    \n",
    "    ### 모델 훈련시키기\n",
    "    history = model.fit(X_list[1], y_list[1], epochs=100, batch_size=4, validation_data=(X_list[2], y_list[2]),\n",
    "                        callbacks=callbacks)\n",
    "    \n",
    "    ### 모델 불러오기\n",
    "    best_model = load_model('./models/part{}_d{}_lstm_tuning.h5'.format(part, num))\n",
    "    \n",
    "    ### 테스트 데이터로 성능 평가\n",
    "    best_model.evaluate(X_list[3], y_list[3])\n",
    "    \n",
    "    ### 테스트 데이터로 예측하기\n",
    "    y_pred_part = best_model.predict(X_list[3])\n",
    "    \n",
    "    ### 예측값을 기존 값 범위로 역변환\n",
    "    y_pred_part_inv = y_list[0].inverse_transform(y_pred_part)\n",
    "    y_test_part_inv = y_list[0].inverse_transform(y_list[3])\n",
    "    \n",
    "    ### mae, mse, rmse 계산\n",
    "    mae = mean_absolute_error(y_test_part_inv, y_pred_part_inv)\n",
    "    mse = mean_squared_error(y_test_part_inv, y_pred_part_inv)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    ### 모델 성능 계산\n",
    "    train_eva = best_model.evaluate(X_list[1], y_list[1])\n",
    "    val_eva = best_model.evaluate(X_list[2], y_list[2])\n",
    "    test_eva = best_model.evaluate(X_list[3], y_list[3])\n",
    "    \n",
    "    result_list = [part, num, train_eva, val_eva, test_eva, mae, mse, rmse]\n",
    "    \n",
    "    return result_list, y_test_part_inv, y_pred_part_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b1c7a5-ff99-4ae9-83b2-877524305903",
   "metadata": {},
   "source": [
    "### 함수 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "08724e02-80df-448c-954e-cb0d64e44168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 형태:  (46, 3, 4)\n",
      "y의 형태:  (46,)\n",
      "X 학습: (32, 3, 4), X 검증: (4, 3, 4), X 평가: (10, 3, 4)\n",
      "y 학습: (32,), y 검증: (4,), y 평가: (10,)\n",
      "Model: \"sequential_987\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1974 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_1975 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_987 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 4s 120ms/step - loss: 0.0100 - val_loss: 0.0010\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0011\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0011\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0012\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0012\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0012\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0013\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0014\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0015\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0016\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0016\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0016\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0018\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0018\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0017\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 0.0011\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0010\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0011\n",
      "X의 형태:  (45, 3, 4)\n",
      "y의 형태:  (45,)\n",
      "X 학습: (31, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (31,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_988\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1976 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_1977 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_988 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 89ms/step - loss: 0.0101 - val_loss: 6.5115e-04\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 7.2072e-04\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 7.8373e-04\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 7.6033e-04\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 7.6332e-04\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 7.8953e-04\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 8.3325e-04\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 8.5718e-04\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 8.3510e-04\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 8.5016e-04\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 8.6021e-04\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 9.0846e-04\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 8.1457e-04\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0093 - val_loss: 7.4034e-04\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 7.4491e-04\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 8.3576e-04\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.0011\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0099\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 6.5115e-04\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0011\n",
      "X의 형태:  (44, 3, 4)\n",
      "y의 형태:  (44,)\n",
      "X 학습: (30, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_989\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1978 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_1979 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_989 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 93ms/step - loss: 0.0100 - val_loss: 6.2729e-04\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 6.4878e-04\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0100 - val_loss: 6.0430e-04\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0099 - val_loss: 5.7246e-04\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 5.5988e-04\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0098 - val_loss: 5.2417e-04\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0096 - val_loss: 5.1330e-04\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0095 - val_loss: 4.7323e-04\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0094 - val_loss: 4.5936e-04\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0093 - val_loss: 4.2950e-04\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0087 - val_loss: 3.6587e-04\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0088 - val_loss: 2.7916e-04\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0086 - val_loss: 1.9360e-04\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0084 - val_loss: 1.5453e-04\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0084 - val_loss: 1.1641e-04\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 1.5865e-04\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 2.4719e-04\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 5.2041e-04\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 8.7807e-04\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0010\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0046 - val_loss: 0.0015\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 0.0023\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 5.3112e-04\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 4.8398e-04\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0051 - val_loss: 4.0727e-04\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 8.5273e-04\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0076\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1641e-04\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.5273e-04\n",
      "X의 형태:  (43, 3, 4)\n",
      "y의 형태:  (43,)\n",
      "X 학습: (30, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_990\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1980 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_1981 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_990 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 6s 97ms/step - loss: 0.0100 - val_loss: 7.3802e-04\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0100 - val_loss: 7.2204e-04\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0099 - val_loss: 6.8178e-04\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0098 - val_loss: 6.7175e-04\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0099 - val_loss: 6.7667e-04\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0096 - val_loss: 6.6574e-04\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 6.8368e-04\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0097 - val_loss: 6.4419e-04\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0096 - val_loss: 6.3602e-04\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 6.5162e-04\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 6.1656e-04\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0093 - val_loss: 6.0043e-04\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 6.2324e-04\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 6.3285e-04\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 5.7355e-04\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0088 - val_loss: 4.8772e-04\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0084 - val_loss: 5.2547e-04\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0081 - val_loss: 4.2230e-04\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0077 - val_loss: 4.2088e-04\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 4.4891e-04\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 4.7491e-04\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 4.9574e-04\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 5.3203e-04\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 6.0772e-04\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 6.4242e-04\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 6.4068e-04\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 7.7602e-04\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0015\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0016\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.0013\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 8.0583e-04\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0074\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.2088e-04\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.0583e-04\n",
      "X의 형태:  (42, 3, 4)\n",
      "y의 형태:  (42,)\n",
      "X 학습: (29, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (29,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_991\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1982 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_1983 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_991 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 85ms/step - loss: 0.0101 - val_loss: 6.5320e-04\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 6.5700e-04\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 6.8163e-04\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 7.1665e-04\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 7.3991e-04\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 8.1118e-04\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 8.6377e-04\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 8.9558e-04\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 9.6548e-04\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0011\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0012\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0012\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0013\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0013\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0013\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0012\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 9.5536e-04\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 6.5320e-04\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.5536e-04\n",
      "X의 형태:  (41, 3, 4)\n",
      "y의 형태:  (41,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_992\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1984 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_1985 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_992 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 4s 109ms/step - loss: 0.0100 - val_loss: 5.9800e-04\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0100 - val_loss: 6.3752e-04\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 6.8103e-04\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 7.2863e-04\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 7.7122e-04\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 8.0501e-04\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 8.7184e-04\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 9.4975e-04\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0010\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0011\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0012\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0012\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0013\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0013\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0013\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0013\n",
      "1/1 [==============================] - 1s 543ms/step - loss: 8.7754e-04\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.9800e-04\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8.7754e-04\n",
      "X의 형태:  (40, 3, 4)\n",
      "y의 형태:  (40,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (8, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (8,)\n",
      "Model: \"sequential_993\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1986 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_1987 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_993 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 5s 328ms/step - loss: 0.0099 - val_loss: 3.0375e-04\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 3.5781e-04\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 4.0499e-04\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 4.2643e-04\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 4.4905e-04\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 4.7565e-04\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 5.0295e-04\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 5.1143e-04\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 5.2713e-04\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 5.1325e-04\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 5.0116e-04\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 5.0214e-04\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 5.1955e-04\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 5.0457e-04\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 5.2503e-04\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 5.0940e-04\n",
      "1/1 [==============================] - 1s 537ms/step - loss: 0.0010\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0099\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.0375e-04\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0010\n",
      "X의 형태:  (46, 3, 4)\n",
      "y의 형태:  (46,)\n",
      "X 학습: (32, 3, 4), X 검증: (4, 3, 4), X 평가: (10, 3, 4)\n",
      "y 학습: (32,), y 검증: (4,), y 평가: (10,)\n",
      "Model: \"sequential_994\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1988 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_1989 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_994 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 4s 92ms/step - loss: 0.0100 - val_loss: 0.0234\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0235\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0238\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0243\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0249\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0255\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0262\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0267\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0277\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0283\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0298\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0306\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0315\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0337\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0343\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0362\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.0070\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.0098\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0234\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0070\n",
      "X의 형태:  (45, 3, 4)\n",
      "y의 형태:  (45,)\n",
      "X 학습: (31, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (31,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_995\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1990 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_1991 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_995 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 116ms/step - loss: 0.0101 - val_loss: 0.0179\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0179\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0180\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0181\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0181\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0181\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0183\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0184\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0183\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0182\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0183\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0190\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0194\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0197\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0200\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0206\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.0083\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0179\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0083\n",
      "X의 형태:  (44, 3, 4)\n",
      "y의 형태:  (44,)\n",
      "X 학습: (30, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_996\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1992 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_1993 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_996 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 6s 90ms/step - loss: 0.0100 - val_loss: 0.0184\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0099 - val_loss: 0.0184\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0098 - val_loss: 0.0183\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 0.0182\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0097 - val_loss: 0.0181\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0097 - val_loss: 0.0181\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0182\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0184\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0184\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0185\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0187\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0190\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0189\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0192\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0194\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0196\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0198\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0203\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0204\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0074 - val_loss: 0.0202\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0204\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.0067\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0095\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0181\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0067\n",
      "X의 형태:  (43, 3, 4)\n",
      "y의 형태:  (43,)\n",
      "X 학습: (30, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_997\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1994 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_1995 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_997 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 108ms/step - loss: 0.0100 - val_loss: 0.0194\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0099 - val_loss: 0.0195\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0195\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0196\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0196\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0197\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0201\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0202\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0203\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0207\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0209\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0214\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0214\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0217\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0217\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0216\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.0073\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0099\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0194\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0073\n",
      "X의 형태:  (42, 3, 4)\n",
      "y의 형태:  (42,)\n",
      "X 학습: (29, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (29,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_998\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1996 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_1997 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_998 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 94ms/step - loss: 0.0100 - val_loss: 0.0191\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0099 - val_loss: 0.0191\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0192\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0193\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0194\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0197\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0199\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0200\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0200\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0200\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0202\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 0.0207\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0210\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0207\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0212\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0219\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0220\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.0070\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0099\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0191\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0070\n",
      "X의 형태:  (41, 3, 4)\n",
      "y의 형태:  (41,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_999\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1998 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_1999 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_999 (Dense)           (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 5s 107ms/step - loss: 0.0100 - val_loss: 0.0197\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0099 - val_loss: 0.0196\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0196\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0197\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0198\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0199\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0198\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0199\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0200\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0200\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0199\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0201\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0202\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0203\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0203\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0205\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0203\n",
      "1/1 [==============================] - 1s 503ms/step - loss: 0.0072\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0099\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0196\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0072\n",
      "X의 형태:  (40, 3, 4)\n",
      "y의 형태:  (40,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (8, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (8,)\n",
      "Model: \"sequential_1000\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2000 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2001 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1000 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 3s 105ms/step - loss: 0.0100 - val_loss: 0.0130\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0099 - val_loss: 0.0129\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.0100 - val_loss: 0.0129\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0099 - val_loss: 0.0129\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.0099 - val_loss: 0.0128\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0099 - val_loss: 0.0127\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 0.0127\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0098 - val_loss: 0.0126\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0098 - val_loss: 0.0126\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0096 - val_loss: 0.0126\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0097 - val_loss: 0.0125\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0126\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0126\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0129\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0130\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0130\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0129\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0129\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0131\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0133\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0132\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0130\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0130\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0130\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0132\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0132\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 0.0088\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0096\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0125\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0088\n",
      "X의 형태:  (46, 3, 4)\n",
      "y의 형태:  (46,)\n",
      "X 학습: (32, 3, 4), X 검증: (4, 3, 4), X 평가: (10, 3, 4)\n",
      "y 학습: (32,), y 검증: (4,), y 평가: (10,)\n",
      "Model: \"sequential_1001\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2002 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2003 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1001 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 93ms/step - loss: 0.0100 - val_loss: 6.5253e-04\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0100 - val_loss: 6.3924e-04\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 6.4130e-04\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0099 - val_loss: 6.2365e-04\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0097 - val_loss: 5.8922e-04\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0096 - val_loss: 5.4410e-04\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0094 - val_loss: 5.1033e-04\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0094 - val_loss: 4.7457e-04\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0090 - val_loss: 4.6023e-04\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0088 - val_loss: 4.0216e-04\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0088 - val_loss: 3.5238e-04\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0081 - val_loss: 3.2148e-04\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0080 - val_loss: 3.0590e-04\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 3.1085e-04\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 3.8611e-04\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 4.4907e-04\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 4.4948e-04\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 4.6363e-04\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 5.5035e-04\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 5.1233e-04\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 4.5995e-04\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 5.0643e-04\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0069 - val_loss: 5.3018e-04\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 5.7555e-04\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 5.1791e-04\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 6.4590e-04\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 8.8990e-04\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0063 - val_loss: 9.5779e-04\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.0040\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.0080\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.0590e-04\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0040\n",
      "X의 형태:  (45, 3, 4)\n",
      "y의 형태:  (45,)\n",
      "X 학습: (31, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (31,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_1002\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2004 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2005 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1002 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 105ms/step - loss: 0.0101 - val_loss: 6.3288e-04\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0099 - val_loss: 6.1876e-04\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0100 - val_loss: 5.8782e-04\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 5.9480e-04\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 5.8894e-04\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 5.8458e-04\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0097 - val_loss: 5.5069e-04\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 5.3532e-04\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 5.2336e-04\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0096 - val_loss: 5.0161e-04\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0096 - val_loss: 4.7320e-04\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0097 - val_loss: 4.1285e-04\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0094 - val_loss: 3.6492e-04\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0095 - val_loss: 3.2103e-04\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 2.7933e-04\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0092 - val_loss: 2.3207e-04\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0091 - val_loss: 1.9562e-04\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0091 - val_loss: 1.3932e-04\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0085 - val_loss: 9.2204e-05\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0087 - val_loss: 6.9829e-05\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0087 - val_loss: 4.3057e-05\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0093 - val_loss: 2.9275e-05\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 3.6662e-05\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 5.4003e-05\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0078 - val_loss: 1.8793e-05\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 2.2620e-05\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 4.5335e-05\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0081 - val_loss: 4.5452e-05\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 3.8696e-04\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 3.9818e-04\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 2.4553e-04\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 2.3233e-05\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0046 - val_loss: 2.9199e-05\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 2.3974e-05\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 3.6870e-05\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0061 - val_loss: 9.3170e-05\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 1.5202e-04\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0057 - val_loss: 3.0409e-04\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 3.5424e-04\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0054 - val_loss: 2.1302e-04\n",
      "1/1 [==============================] - 1s 502ms/step - loss: 0.0064\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0066\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.8793e-05\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0064\n",
      "X의 형태:  (44, 3, 4)\n",
      "y의 형태:  (44,)\n",
      "X 학습: (30, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_1003\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2006 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2007 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1003 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 88ms/step - loss: 0.0101 - val_loss: 4.3397e-04\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0101 - val_loss: 4.2780e-04\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 4.5966e-04\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 4.7638e-04\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 4.8073e-04\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 4.9515e-04\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 4.7802e-04\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 4.8247e-04\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 4.6915e-04\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 4.7486e-04\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 4.7643e-04\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 4.7467e-04\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 4.7950e-04\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 4.9032e-04\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 5.1654e-04\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 5.4549e-04\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 5.6276e-04\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 0.0064\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0101\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.2780e-04\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0064\n",
      "X의 형태:  (43, 3, 4)\n",
      "y의 형태:  (43,)\n",
      "X 학습: (30, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_1004\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2008 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2009 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1004 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 6s 253ms/step - loss: 0.0100 - val_loss: 5.4184e-04\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0099 - val_loss: 5.6764e-04\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 5.9771e-04\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 6.1153e-04\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 6.2311e-04\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 6.3251e-04\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 6.2483e-04\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 6.5859e-04\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 6.7985e-04\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 6.8567e-04\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 7.2305e-04\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 7.3634e-04\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 7.3790e-04\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 7.6583e-04\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 7.9461e-04\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 8.7072e-04\n",
      "1/1 [==============================] - 1s 565ms/step - loss: 0.0068\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 5.4184e-04\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0068\n",
      "X의 형태:  (42, 3, 4)\n",
      "y의 형태:  (42,)\n",
      "X 학습: (29, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (29,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_1005\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2010 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2011 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1005 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 98ms/step - loss: 0.0100 - val_loss: 5.4302e-04\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0100 - val_loss: 6.0958e-04\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 6.4091e-04\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 6.7596e-04\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 7.8645e-04\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 8.0796e-04\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 8.3977e-04\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 8.8673e-04\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 9.4011e-04\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0011\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0010\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 9.1332e-04\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 9.0968e-04\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 9.2576e-04\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 9.7447e-04\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 8.5215e-04\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 0.0066\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0099\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.4302e-04\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0066\n",
      "X의 형태:  (41, 3, 4)\n",
      "y의 형태:  (41,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_1006\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2012 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2013 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1006 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 4s 117ms/step - loss: 0.0099 - val_loss: 4.1755e-04\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 4.4766e-04\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 4.6891e-04\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 4.6689e-04\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 4.9995e-04\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 5.3153e-04\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 5.8771e-04\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 6.4148e-04\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 6.5003e-04\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 6.9204e-04\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 7.0691e-04\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 6.5598e-04\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 6.7570e-04\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 5.8802e-04\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 4.7399e-04\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0093 - val_loss: 4.0510e-04\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 4.1466e-04\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 4.2727e-04\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 4.1687e-04\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0092 - val_loss: 4.0254e-04\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.0091 - val_loss: 3.3701e-04\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0092 - val_loss: 3.0902e-04\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 3.6136e-04\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 3.9695e-04\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 3.8370e-04\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 4.9815e-04\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 5.4020e-04\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 5.7027e-04\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 5.3658e-04\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 4.6318e-04\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 3.8719e-04\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 4.6098e-04\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 4.8754e-04\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 4.5513e-04\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 6.5699e-04\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 6.3851e-04\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 6.6563e-04\n",
      "1/1 [==============================] - 1s 544ms/step - loss: 0.0060\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0090\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.0902e-04\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0060\n",
      "X의 형태:  (40, 3, 4)\n",
      "y의 형태:  (40,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (8, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (8,)\n",
      "Model: \"sequential_1007\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2014 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2015 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1007 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 5s 141ms/step - loss: 0.0100 - val_loss: 2.6770e-04\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 2.8008e-04\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 2.9447e-04\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 2.9354e-04\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 3.3048e-04\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 3.3995e-04\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 3.6592e-04\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 3.9951e-04\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 4.0270e-04\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 4.5293e-04\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 5.2506e-04\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 5.3878e-04\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 5.7925e-04\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 5.0475e-04\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 3.8524e-04\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 3.2988e-04\n",
      "1/1 [==============================] - 1s 578ms/step - loss: 0.0064\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0099\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.6770e-04\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0064\n",
      "X의 형태:  (46, 3, 4)\n",
      "y의 형태:  (46,)\n",
      "X 학습: (32, 3, 4), X 검증: (4, 3, 4), X 평가: (10, 3, 4)\n",
      "y 학습: (32,), y 검증: (4,), y 평가: (10,)\n",
      "Model: \"sequential_1008\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2016 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2017 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1008 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 4s 118ms/step - loss: 0.0101 - val_loss: 3.8123e-04\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0099 - val_loss: 3.4047e-04\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0098 - val_loss: 3.0350e-04\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0097 - val_loss: 2.5489e-04\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 2.0400e-04\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0094 - val_loss: 1.5010e-04\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 1.0720e-04\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0091 - val_loss: 7.0094e-05\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 5.5005e-05\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 6.3536e-05\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 9.6798e-05\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 1.3168e-04\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 1.4879e-04\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 1.6312e-04\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 1.8307e-04\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 1.9122e-04\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 2.1449e-04\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 2.2028e-04\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 2.5609e-04\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0076 - val_loss: 3.2320e-04\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0072 - val_loss: 3.4382e-04\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0076 - val_loss: 4.0427e-04\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 4.5221e-04\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 4.9399e-04\n",
      "1/1 [==============================] - 1s 534ms/step - loss: 6.6859e-05\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 0.0086\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.5005e-05\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6.6859e-05\n",
      "X의 형태:  (45, 3, 4)\n",
      "y의 형태:  (45,)\n",
      "X 학습: (31, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (31,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_1009\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2018 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2019 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1009 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 98ms/step - loss: 0.0100 - val_loss: 3.1822e-04\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0100 - val_loss: 2.7755e-04\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 2.3408e-04\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 2.2972e-04\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 2.1742e-04\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 1.9175e-04\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0096 - val_loss: 1.4433e-04\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0096 - val_loss: 1.0132e-04\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 7.4267e-05\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0093 - val_loss: 5.5603e-05\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 5.9365e-05\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 1.3029e-04\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 1.9944e-04\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 2.2252e-04\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 2.7439e-04\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 4.0054e-04\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 2.6496e-04\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 3.0249e-04\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 3.2223e-04\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 3.8278e-04\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 5.5898e-04\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 5.5077e-04\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 5.1332e-04\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 3.4170e-04\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 3.2953e-04\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 7.3715e-05\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0093\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.5603e-05\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.3715e-05\n",
      "X의 형태:  (44, 3, 4)\n",
      "y의 형태:  (44,)\n",
      "X 학습: (30, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_1010\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2020 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2021 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1010 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 7s 129ms/step - loss: 0.0101 - val_loss: 2.3132e-04\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0100 - val_loss: 2.0364e-04\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 1.9295e-04\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 1.7247e-04\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0099 - val_loss: 1.4811e-04\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0097 - val_loss: 1.2807e-04\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 9.9576e-05\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0095 - val_loss: 8.2892e-05\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0094 - val_loss: 6.6212e-05\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0095 - val_loss: 6.2201e-05\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 8.1298e-05\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 1.2817e-04\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 2.1516e-04\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 3.1468e-04\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 3.9806e-04\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 4.1383e-04\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 4.2135e-04\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 3.5212e-04\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 3.3332e-04\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 4.2117e-04\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 5.6993e-04\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 6.9806e-04\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 6.6181e-04\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 7.4835e-04\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 7.8889e-04\n",
      "1/1 [==============================] - 1s 569ms/step - loss: 5.7631e-05\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0093\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.2201e-05\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.7631e-05\n",
      "X의 형태:  (43, 3, 4)\n",
      "y의 형태:  (43,)\n",
      "X 학습: (30, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_1011\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2022 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2023 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1011 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 93ms/step - loss: 0.0102 - val_loss: 1.8559e-04\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0102 - val_loss: 1.8273e-04\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0101 - val_loss: 1.7975e-04\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0100 - val_loss: 1.6620e-04\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 1.5130e-04\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0099 - val_loss: 1.3077e-04\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 1.0262e-04\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 8.5235e-05\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 6.6263e-05\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0097 - val_loss: 4.7935e-05\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0097 - val_loss: 3.7603e-05\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0094 - val_loss: 3.3144e-05\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 4.4228e-05\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 7.0631e-05\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 1.0701e-04\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 1.3442e-04\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 1.7747e-04\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 1.6854e-04\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 1.3239e-04\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 9.7479e-05\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 1.0243e-04\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 1.6823e-04\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 2.8318e-04\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 3.8392e-04\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 4.7798e-04\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 4.9622e-04\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 4.9799e-04\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 5.8277e-05\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0094\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.3144e-05\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.8277e-05\n",
      "X의 형태:  (42, 3, 4)\n",
      "y의 형태:  (42,)\n",
      "X 학습: (29, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (29,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_1012\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2024 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2025 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1012 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 95ms/step - loss: 0.0101 - val_loss: 1.3574e-04\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0101 - val_loss: 1.2703e-04\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 1.1705e-04\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0100 - val_loss: 1.0512e-04\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0099 - val_loss: 9.5415e-05\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 7.8788e-05\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0098 - val_loss: 6.7666e-05\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 6.2383e-05\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 6.1374e-05\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 6.2908e-05\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 6.1861e-05\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 6.0803e-05\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0095 - val_loss: 6.0095e-05\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 5.9590e-05\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0095 - val_loss: 5.9465e-05\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 6.0425e-05\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 6.2012e-05\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 6.0100e-05\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 6.0955e-05\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 6.4610e-05\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 7.3356e-05\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 7.5010e-05\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 7.0227e-05\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 7.4590e-05\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 7.3297e-05\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 8.9031e-05\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 1.1911e-04\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 8.3108e-05\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 8.6920e-05\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0085 - val_loss: 9.2685e-05\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 5.1312e-05\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0093\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.9465e-05\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.1312e-05\n",
      "X의 형태:  (41, 3, 4)\n",
      "y의 형태:  (41,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_1013\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2026 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2027 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1013 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 5s 119ms/step - loss: 0.0100 - val_loss: 7.1216e-05\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0100 - val_loss: 7.1103e-05\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0099 - val_loss: 6.8651e-05\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 6.1873e-05\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0098 - val_loss: 5.9320e-05\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0099 - val_loss: 5.7564e-05\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 5.8212e-05\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 6.0249e-05\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 6.7505e-05\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 7.2222e-05\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 7.6873e-05\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 8.8109e-05\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 8.8747e-05\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 1.1109e-04\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 1.1879e-04\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 1.5126e-04\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 1.4070e-04\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 1.4532e-04\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 1.4789e-04\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 1.2925e-04\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 1.2816e-04\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 3.2248e-05\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0098\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 5.7564e-05\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2248e-05\n",
      "X의 형태:  (40, 3, 4)\n",
      "y의 형태:  (40,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (8, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (8,)\n",
      "Model: \"sequential_1014\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2028 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2029 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1014 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 3s 98ms/step - loss: 0.0101 - val_loss: 4.6687e-05\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 4.8316e-05\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 4.6918e-05\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 4.3039e-05\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 4.2403e-05\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 4.0699e-05\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 4.2525e-05\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 4.3614e-05\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 5.1362e-05\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 5.6992e-05\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 5.9966e-05\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 6.3771e-05\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 6.3252e-05\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 7.2711e-05\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 8.1041e-05\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 8.7053e-05\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 8.2659e-05\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 8.6024e-05\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 1.0366e-04\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 1.2268e-04\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 1.4126e-04\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 3.5316e-05\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0098\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0699e-05\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.5316e-05\n",
      "X의 형태:  (46, 3, 4)\n",
      "y의 형태:  (46,)\n",
      "X 학습: (32, 3, 4), X 검증: (4, 3, 4), X 평가: (10, 3, 4)\n",
      "y 학습: (32,), y 검증: (4,), y 평가: (10,)\n",
      "Model: \"sequential_1015\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2030 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2031 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1015 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 4s 93ms/step - loss: 0.0098 - val_loss: 0.0049\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0097 - val_loss: 0.0048\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0094 - val_loss: 0.0048\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0047\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0081 - val_loss: 0.0045\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0046\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0048\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0045\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.0148\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.0055\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0038\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0148\n",
      "X의 형태:  (45, 3, 4)\n",
      "y의 형태:  (45,)\n",
      "X 학습: (31, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (31,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_1016\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2032 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2033 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1016 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 6s 106ms/step - loss: 0.0098 - val_loss: 0.0078\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0094 - val_loss: 0.0078\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0095 - val_loss: 0.0078\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0078\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0089 - val_loss: 0.0078\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0078\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0078\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 0.0083\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0044 - val_loss: 0.0086\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0090\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0089\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0036 - val_loss: 0.0086\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0082\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0078\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0081\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0080\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0081\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0078\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.0170\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0085\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0078\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0170\n",
      "X의 형태:  (44, 3, 4)\n",
      "y의 형태:  (44,)\n",
      "X 학습: (30, 3, 4), X 검증: (5, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (5,), y 평가: (9,)\n",
      "Model: \"sequential_1017\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2034 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2035 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1017 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 98ms/step - loss: 0.0099 - val_loss: 0.0079\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0096 - val_loss: 0.0079\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0079\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0079\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0080\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0081\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 0.0082\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0085\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0061 - val_loss: 0.0090\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0056 - val_loss: 0.0097\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.0107\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0060 - val_loss: 0.0123\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 0.0135\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.0146\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0043 - val_loss: 0.0163\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.0161\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.0152\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.0188\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0094\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0079\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0188\n",
      "X의 형태:  (43, 3, 4)\n",
      "y의 형태:  (43,)\n",
      "X 학습: (30, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (30,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_1018\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2036 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2037 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1018 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 84ms/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0094 - val_loss: 0.0086\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0089\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0091\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0084 - val_loss: 0.0096\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0114\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0066 - val_loss: 0.0127\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.0150\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0177\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0205\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0223\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0058 - val_loss: 0.0223\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0049 - val_loss: 0.0240\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0226\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0190\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0098\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0083\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0190\n",
      "X의 형태:  (42, 3, 4)\n",
      "y의 형태:  (42,)\n",
      "X 학습: (29, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (29,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_1019\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2038 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2039 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1019 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 87ms/step - loss: 0.0099 - val_loss: 0.0089\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0101\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0108\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0115\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0073 - val_loss: 0.0130\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0065 - val_loss: 0.0151\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0061 - val_loss: 0.0191\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0236\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 0.0252\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0275\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0292\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0323\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0053 - val_loss: 0.0301\n",
      "1/1 [==============================] - 1s 529ms/step - loss: 0.0195\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0097\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0089\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0195\n",
      "X의 형태:  (41, 3, 4)\n",
      "y의 형태:  (41,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (9, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (9,)\n",
      "Model: \"sequential_1020\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2040 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2041 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1020 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 3s 111ms/step - loss: 0.0101 - val_loss: 0.0086\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0087\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0090\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0091\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0093\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0094\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0097\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0080 - val_loss: 0.0115\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0125\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0147\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0177\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.0219\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.0199\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0086\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0199\n",
      "X의 형태:  (40, 3, 4)\n",
      "y의 형태:  (40,)\n",
      "X 학습: (28, 3, 4), X 검증: (4, 3, 4), X 평가: (8, 3, 4)\n",
      "y 학습: (28,), y 검증: (4,), y 평가: (8,)\n",
      "Model: \"sequential_1021\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2042 (LSTM)            (None, 3, 32)             4736      \n",
      "                                                                 \n",
      " lstm_2043 (LSTM)            (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1021 (Dense)          (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089\n",
      "Trainable params: 13,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 3s 107ms/step - loss: 0.0100 - val_loss: 0.0110\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0097 - val_loss: 0.0110\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0095 - val_loss: 0.0109\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0110\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0110\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0111\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0113\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0114\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0116\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0119\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0078 - val_loss: 0.0124\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0128\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0136\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0148\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0153\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0174\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0075 - val_loss: 0.0190\n",
      "1/1 [==============================] - 1s 551ms/step - loss: 0.0212\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0093\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0109\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0212\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['part_number', 'pred_day','train_evaluate', 'val_evaluate', 'test_evaluate', 'mae', 'mse', 'rmse'])\n",
    "\n",
    "for part in [6, 15, 16, 29, 94]:\n",
    "    data = getData(part)\n",
    "    \n",
    "    for num in range(1, 8, 1) :\n",
    "        data_new = getCols(data, num)\n",
    "\n",
    "        X_list, y_list = getSplitData(data_new, num)\n",
    "        result_list, y_test_part_inv, y_pred_part_inv = getLSTMTuningModel(part, num, X_list, y_list)\n",
    "        \n",
    "        df.loc[len(df)] = result_list\n",
    "df.to_csv('./data_new/lstm_결과_튜닝후.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c3fc3b-871e-4271-933c-60e45e9bb7ae",
   "metadata": {},
   "source": [
    "### 튜닝 전/후 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8189a3bd-9f28-407b-b9de-73ec0a69b68f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part_number</th>\n",
       "      <th>pred_day</th>\n",
       "      <th>train_evaluate</th>\n",
       "      <th>val_evaluate</th>\n",
       "      <th>test_evaluate</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994169</td>\n",
       "      <td>0.134280</td>\n",
       "      <td>0.114758</td>\n",
       "      <td>7.446828</td>\n",
       "      <td>99.603179</td>\n",
       "      <td>9.980139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.001938</td>\n",
       "      <td>0.054181</td>\n",
       "      <td>0.095073</td>\n",
       "      <td>7.164919</td>\n",
       "      <td>85.178664</td>\n",
       "      <td>9.229229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.743079</td>\n",
       "      <td>0.012324</td>\n",
       "      <td>0.065070</td>\n",
       "      <td>6.330399</td>\n",
       "      <td>60.107657</td>\n",
       "      <td>7.752913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.820884</td>\n",
       "      <td>0.045073</td>\n",
       "      <td>0.087792</td>\n",
       "      <td>7.460961</td>\n",
       "      <td>80.965769</td>\n",
       "      <td>8.998098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.023650</td>\n",
       "      <td>0.038999</td>\n",
       "      <td>0.064452</td>\n",
       "      <td>6.434555</td>\n",
       "      <td>61.326307</td>\n",
       "      <td>7.831111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.003540</td>\n",
       "      <td>0.052521</td>\n",
       "      <td>0.080071</td>\n",
       "      <td>6.991891</td>\n",
       "      <td>78.684121</td>\n",
       "      <td>8.870407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.000402</td>\n",
       "      <td>0.022159</td>\n",
       "      <td>0.090991</td>\n",
       "      <td>7.730541</td>\n",
       "      <td>89.494174</td>\n",
       "      <td>9.460136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.001315</td>\n",
       "      <td>2.303906</td>\n",
       "      <td>0.734188</td>\n",
       "      <td>6.713324</td>\n",
       "      <td>85.755857</td>\n",
       "      <td>9.260446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.996900</td>\n",
       "      <td>1.842325</td>\n",
       "      <td>0.793552</td>\n",
       "      <td>7.364521</td>\n",
       "      <td>93.728294</td>\n",
       "      <td>9.681337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.984347</td>\n",
       "      <td>1.899140</td>\n",
       "      <td>0.604273</td>\n",
       "      <td>6.738096</td>\n",
       "      <td>73.257395</td>\n",
       "      <td>8.559053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.967179</td>\n",
       "      <td>2.036656</td>\n",
       "      <td>0.791501</td>\n",
       "      <td>7.580844</td>\n",
       "      <td>98.467082</td>\n",
       "      <td>9.923058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.012157</td>\n",
       "      <td>1.889159</td>\n",
       "      <td>0.770697</td>\n",
       "      <td>7.722141</td>\n",
       "      <td>98.542886</td>\n",
       "      <td>9.926877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.984450</td>\n",
       "      <td>2.020381</td>\n",
       "      <td>0.547493</td>\n",
       "      <td>6.740878</td>\n",
       "      <td>71.997399</td>\n",
       "      <td>8.485128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.949606</td>\n",
       "      <td>1.244308</td>\n",
       "      <td>0.758167</td>\n",
       "      <td>8.326597</td>\n",
       "      <td>105.946065</td>\n",
       "      <td>10.293010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.804409</td>\n",
       "      <td>0.045130</td>\n",
       "      <td>0.504227</td>\n",
       "      <td>12.290410</td>\n",
       "      <td>200.512262</td>\n",
       "      <td>14.160235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.803940</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.589706</td>\n",
       "      <td>12.698964</td>\n",
       "      <td>237.255563</td>\n",
       "      <td>15.403102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.981943</td>\n",
       "      <td>0.059969</td>\n",
       "      <td>0.779090</td>\n",
       "      <td>15.979574</td>\n",
       "      <td>319.250369</td>\n",
       "      <td>17.867579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.981042</td>\n",
       "      <td>0.064584</td>\n",
       "      <td>0.724600</td>\n",
       "      <td>15.170824</td>\n",
       "      <td>292.400361</td>\n",
       "      <td>17.099718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.996052</td>\n",
       "      <td>0.045918</td>\n",
       "      <td>0.640259</td>\n",
       "      <td>14.219405</td>\n",
       "      <td>262.798379</td>\n",
       "      <td>16.211057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.010076</td>\n",
       "      <td>0.031351</td>\n",
       "      <td>0.589499</td>\n",
       "      <td>13.517250</td>\n",
       "      <td>246.031744</td>\n",
       "      <td>15.685399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.997465</td>\n",
       "      <td>0.013704</td>\n",
       "      <td>0.573218</td>\n",
       "      <td>13.388143</td>\n",
       "      <td>234.693860</td>\n",
       "      <td>15.319721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.887785</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>7.772137</td>\n",
       "      <td>100.214409</td>\n",
       "      <td>10.010715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.936013</td>\n",
       "      <td>0.004146</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>7.418518</td>\n",
       "      <td>124.577109</td>\n",
       "      <td>11.161412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.946743</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>9.039130</td>\n",
       "      <td>121.494562</td>\n",
       "      <td>11.022457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.939586</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.005536</td>\n",
       "      <td>8.295553</td>\n",
       "      <td>96.625320</td>\n",
       "      <td>9.829818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.954355</td>\n",
       "      <td>0.008119</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>7.168521</td>\n",
       "      <td>73.728830</td>\n",
       "      <td>8.586549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>29.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.961412</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.004353</td>\n",
       "      <td>7.110667</td>\n",
       "      <td>79.135385</td>\n",
       "      <td>8.895807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.969690</td>\n",
       "      <td>0.004250</td>\n",
       "      <td>0.004214</td>\n",
       "      <td>7.316395</td>\n",
       "      <td>75.391557</td>\n",
       "      <td>8.682831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.924590</td>\n",
       "      <td>0.485554</td>\n",
       "      <td>1.742527</td>\n",
       "      <td>5.410462</td>\n",
       "      <td>36.565832</td>\n",
       "      <td>6.046969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>94.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.661975</td>\n",
       "      <td>0.782854</td>\n",
       "      <td>1.665112</td>\n",
       "      <td>5.250827</td>\n",
       "      <td>34.314143</td>\n",
       "      <td>5.857827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>94.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.940117</td>\n",
       "      <td>0.795087</td>\n",
       "      <td>1.900383</td>\n",
       "      <td>5.597698</td>\n",
       "      <td>38.955738</td>\n",
       "      <td>6.241453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>94.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.990963</td>\n",
       "      <td>0.886194</td>\n",
       "      <td>1.973593</td>\n",
       "      <td>5.696226</td>\n",
       "      <td>39.726248</td>\n",
       "      <td>6.302876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>94.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.984088</td>\n",
       "      <td>0.941517</td>\n",
       "      <td>1.930532</td>\n",
       "      <td>5.621025</td>\n",
       "      <td>38.289262</td>\n",
       "      <td>6.187832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>94.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000565</td>\n",
       "      <td>0.904456</td>\n",
       "      <td>1.925458</td>\n",
       "      <td>5.541331</td>\n",
       "      <td>37.438371</td>\n",
       "      <td>6.118690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>94.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.841848</td>\n",
       "      <td>0.904864</td>\n",
       "      <td>1.891582</td>\n",
       "      <td>5.610744</td>\n",
       "      <td>35.515409</td>\n",
       "      <td>5.959481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    part_number  pred_day  train_evaluate  val_evaluate  test_evaluate  \\\n",
       "0           6.0       1.0        0.994169      0.134280       0.114758   \n",
       "1           6.0       2.0        1.001938      0.054181       0.095073   \n",
       "2           6.0       3.0        0.743079      0.012324       0.065070   \n",
       "3           6.0       4.0        0.820884      0.045073       0.087792   \n",
       "4           6.0       5.0        1.023650      0.038999       0.064452   \n",
       "5           6.0       6.0        1.003540      0.052521       0.080071   \n",
       "6           6.0       7.0        1.000402      0.022159       0.090991   \n",
       "7          15.0       1.0        1.001315      2.303906       0.734188   \n",
       "8          15.0       2.0        0.996900      1.842325       0.793552   \n",
       "9          15.0       3.0        0.984347      1.899140       0.604273   \n",
       "10         15.0       4.0        0.967179      2.036656       0.791501   \n",
       "11         15.0       5.0        1.012157      1.889159       0.770697   \n",
       "12         15.0       6.0        0.984450      2.020381       0.547493   \n",
       "13         15.0       7.0        0.949606      1.244308       0.758167   \n",
       "14         16.0       1.0        0.804409      0.045130       0.504227   \n",
       "15         16.0       2.0        0.803940      0.002279       0.589706   \n",
       "16         16.0       3.0        0.981943      0.059969       0.779090   \n",
       "17         16.0       4.0        0.981042      0.064584       0.724600   \n",
       "18         16.0       5.0        0.996052      0.045918       0.640259   \n",
       "19         16.0       6.0        1.010076      0.031351       0.589499   \n",
       "20         16.0       7.0        0.997465      0.013704       0.573218   \n",
       "21         29.0       1.0        0.887785      0.005369       0.005962   \n",
       "22         29.0       2.0        0.936013      0.004146       0.007208   \n",
       "23         29.0       3.0        0.946743      0.005398       0.006881   \n",
       "24         29.0       4.0        0.939586      0.004704       0.005536   \n",
       "25         29.0       5.0        0.954355      0.008119       0.004139   \n",
       "26         29.0       6.0        0.961412      0.006271       0.004353   \n",
       "27         29.0       7.0        0.969690      0.004250       0.004214   \n",
       "28         94.0       1.0        0.924590      0.485554       1.742527   \n",
       "29         94.0       2.0        0.661975      0.782854       1.665112   \n",
       "30         94.0       3.0        0.940117      0.795087       1.900383   \n",
       "31         94.0       4.0        0.990963      0.886194       1.973593   \n",
       "32         94.0       5.0        0.984088      0.941517       1.930532   \n",
       "33         94.0       6.0        1.000565      0.904456       1.925458   \n",
       "34         94.0       7.0        0.841848      0.904864       1.891582   \n",
       "\n",
       "          mae         mse       rmse  \n",
       "0    7.446828   99.603179   9.980139  \n",
       "1    7.164919   85.178664   9.229229  \n",
       "2    6.330399   60.107657   7.752913  \n",
       "3    7.460961   80.965769   8.998098  \n",
       "4    6.434555   61.326307   7.831111  \n",
       "5    6.991891   78.684121   8.870407  \n",
       "6    7.730541   89.494174   9.460136  \n",
       "7    6.713324   85.755857   9.260446  \n",
       "8    7.364521   93.728294   9.681337  \n",
       "9    6.738096   73.257395   8.559053  \n",
       "10   7.580844   98.467082   9.923058  \n",
       "11   7.722141   98.542886   9.926877  \n",
       "12   6.740878   71.997399   8.485128  \n",
       "13   8.326597  105.946065  10.293010  \n",
       "14  12.290410  200.512262  14.160235  \n",
       "15  12.698964  237.255563  15.403102  \n",
       "16  15.979574  319.250369  17.867579  \n",
       "17  15.170824  292.400361  17.099718  \n",
       "18  14.219405  262.798379  16.211057  \n",
       "19  13.517250  246.031744  15.685399  \n",
       "20  13.388143  234.693860  15.319721  \n",
       "21   7.772137  100.214409  10.010715  \n",
       "22   7.418518  124.577109  11.161412  \n",
       "23   9.039130  121.494562  11.022457  \n",
       "24   8.295553   96.625320   9.829818  \n",
       "25   7.168521   73.728830   8.586549  \n",
       "26   7.110667   79.135385   8.895807  \n",
       "27   7.316395   75.391557   8.682831  \n",
       "28   5.410462   36.565832   6.046969  \n",
       "29   5.250827   34.314143   5.857827  \n",
       "30   5.597698   38.955738   6.241453  \n",
       "31   5.696226   39.726248   6.302876  \n",
       "32   5.621025   38.289262   6.187832  \n",
       "33   5.541331   37.438371   6.118690  \n",
       "34   5.610744   35.515409   5.959481  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 튜닝 전 loss 확인\n",
    "df_before = pd.read_csv(\"./data_new/lstm_결과.csv\")\n",
    "df_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9b1bf891-7ac4-471e-af5e-a8269642c27f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part_number</th>\n",
       "      <th>pred_day</th>\n",
       "      <th>train_evaluate</th>\n",
       "      <th>val_evaluate</th>\n",
       "      <th>test_evaluate</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009852</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>7.212905</td>\n",
       "      <td>94.467174</td>\n",
       "      <td>9.719423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>7.497284</td>\n",
       "      <td>96.451575</td>\n",
       "      <td>9.820976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.007636</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>6.708657</td>\n",
       "      <td>78.769720</td>\n",
       "      <td>8.875231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.007412</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>7.274001</td>\n",
       "      <td>74.317182</td>\n",
       "      <td>8.620741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>7.307207</td>\n",
       "      <td>90.903285</td>\n",
       "      <td>9.534321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>7.254711</td>\n",
       "      <td>86.233902</td>\n",
       "      <td>9.286221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.009877</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>8.192920</td>\n",
       "      <td>100.059389</td>\n",
       "      <td>10.002969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>0.023447</td>\n",
       "      <td>0.006972</td>\n",
       "      <td>6.494264</td>\n",
       "      <td>81.432742</td>\n",
       "      <td>9.024009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.009984</td>\n",
       "      <td>0.017873</td>\n",
       "      <td>0.008253</td>\n",
       "      <td>7.481616</td>\n",
       "      <td>97.479091</td>\n",
       "      <td>9.873150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.018122</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>6.965995</td>\n",
       "      <td>81.512813</td>\n",
       "      <td>9.028445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.009922</td>\n",
       "      <td>0.019425</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>7.234211</td>\n",
       "      <td>91.288036</td>\n",
       "      <td>9.554477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.009867</td>\n",
       "      <td>0.019128</td>\n",
       "      <td>0.007038</td>\n",
       "      <td>7.156755</td>\n",
       "      <td>89.985044</td>\n",
       "      <td>9.486045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.009911</td>\n",
       "      <td>0.019556</td>\n",
       "      <td>0.007235</td>\n",
       "      <td>7.403436</td>\n",
       "      <td>95.147501</td>\n",
       "      <td>9.754358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.009649</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.008774</td>\n",
       "      <td>8.912251</td>\n",
       "      <td>122.601207</td>\n",
       "      <td>11.072543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.004013</td>\n",
       "      <td>10.548755</td>\n",
       "      <td>159.581536</td>\n",
       "      <td>12.632559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.006599</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.006396</td>\n",
       "      <td>12.896794</td>\n",
       "      <td>257.342238</td>\n",
       "      <td>16.041890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.006364</td>\n",
       "      <td>14.230575</td>\n",
       "      <td>260.777117</td>\n",
       "      <td>16.148595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.006774</td>\n",
       "      <td>14.577408</td>\n",
       "      <td>273.364474</td>\n",
       "      <td>16.533737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>14.518509</td>\n",
       "      <td>271.221356</td>\n",
       "      <td>16.468799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.008995</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.005971</td>\n",
       "      <td>13.790661</td>\n",
       "      <td>249.219032</td>\n",
       "      <td>15.786673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.009925</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>14.531803</td>\n",
       "      <td>263.632176</td>\n",
       "      <td>16.236754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008595</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>8.256720</td>\n",
       "      <td>112.380441</td>\n",
       "      <td>10.600964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.009273</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>8.958523</td>\n",
       "      <td>127.402469</td>\n",
       "      <td>11.287270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>7.895857</td>\n",
       "      <td>101.761643</td>\n",
       "      <td>10.087698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.009403</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>6.999508</td>\n",
       "      <td>101.708064</td>\n",
       "      <td>10.085042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.009321</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>8.439687</td>\n",
       "      <td>91.397712</td>\n",
       "      <td>9.560215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>29.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.009753</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>6.262075</td>\n",
       "      <td>58.625635</td>\n",
       "      <td>7.656738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.009805</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>6.951790</td>\n",
       "      <td>63.185512</td>\n",
       "      <td>7.948931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>0.014786</td>\n",
       "      <td>4.814592</td>\n",
       "      <td>31.027856</td>\n",
       "      <td>5.570265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>94.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.008480</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>0.016965</td>\n",
       "      <td>5.365153</td>\n",
       "      <td>34.960071</td>\n",
       "      <td>5.912704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>94.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>0.007889</td>\n",
       "      <td>0.018826</td>\n",
       "      <td>5.558473</td>\n",
       "      <td>38.590180</td>\n",
       "      <td>6.212100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>94.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.009819</td>\n",
       "      <td>0.008341</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>5.571360</td>\n",
       "      <td>38.331433</td>\n",
       "      <td>6.191238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>94.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.009722</td>\n",
       "      <td>0.008874</td>\n",
       "      <td>0.019493</td>\n",
       "      <td>5.642085</td>\n",
       "      <td>38.660956</td>\n",
       "      <td>6.217794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>94.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.009987</td>\n",
       "      <td>0.008619</td>\n",
       "      <td>0.019867</td>\n",
       "      <td>5.645657</td>\n",
       "      <td>38.629135</td>\n",
       "      <td>6.215234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>94.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.009318</td>\n",
       "      <td>0.010948</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>5.777380</td>\n",
       "      <td>39.782777</td>\n",
       "      <td>6.307359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    part_number  pred_day  train_evaluate  val_evaluate  test_evaluate  \\\n",
       "0           6.0       1.0        0.009852      0.001025       0.001088   \n",
       "1           6.0       2.0        0.009940      0.000651       0.001077   \n",
       "2           6.0       3.0        0.007636      0.000116       0.000853   \n",
       "3           6.0       4.0        0.007412      0.000421       0.000806   \n",
       "4           6.0       5.0        0.009999      0.000653       0.000955   \n",
       "5           6.0       6.0        0.010002      0.000598       0.000878   \n",
       "6           6.0       7.0        0.009877      0.000304       0.001017   \n",
       "7          15.0       1.0        0.009841      0.023447       0.006972   \n",
       "8          15.0       2.0        0.009984      0.017873       0.008253   \n",
       "9          15.0       3.0        0.009497      0.018122       0.006724   \n",
       "10         15.0       4.0        0.009922      0.019425       0.007338   \n",
       "11         15.0       5.0        0.009867      0.019128       0.007038   \n",
       "12         15.0       6.0        0.009911      0.019556       0.007235   \n",
       "13         15.0       7.0        0.009649      0.012500       0.008774   \n",
       "14         16.0       1.0        0.007975      0.000306       0.004013   \n",
       "15         16.0       2.0        0.006599      0.000019       0.006396   \n",
       "16         16.0       3.0        0.010060      0.000428       0.006364   \n",
       "17         16.0       4.0        0.009967      0.000542       0.006774   \n",
       "18         16.0       5.0        0.009940      0.000543       0.006608   \n",
       "19         16.0       6.0        0.008995      0.000309       0.005971   \n",
       "20         16.0       7.0        0.009925      0.000268       0.006439   \n",
       "21         29.0       1.0        0.008595      0.000055       0.000067   \n",
       "22         29.0       2.0        0.009273      0.000056       0.000074   \n",
       "23         29.0       3.0        0.009310      0.000062       0.000058   \n",
       "24         29.0       4.0        0.009403      0.000033       0.000058   \n",
       "25         29.0       5.0        0.009321      0.000059       0.000051   \n",
       "26         29.0       6.0        0.009753      0.000058       0.000032   \n",
       "27         29.0       7.0        0.009805      0.000041       0.000035   \n",
       "28         94.0       1.0        0.005502      0.003849       0.014786   \n",
       "29         94.0       2.0        0.008480      0.007773       0.016965   \n",
       "30         94.0       3.0        0.009371      0.007889       0.018826   \n",
       "31         94.0       4.0        0.009819      0.008341       0.019043   \n",
       "32         94.0       5.0        0.009722      0.008874       0.019493   \n",
       "33         94.0       6.0        0.009987      0.008619       0.019867   \n",
       "34         94.0       7.0        0.009318      0.010948       0.021189   \n",
       "\n",
       "          mae         mse       rmse  \n",
       "0    7.212905   94.467174   9.719423  \n",
       "1    7.497284   96.451575   9.820976  \n",
       "2    6.708657   78.769720   8.875231  \n",
       "3    7.274001   74.317182   8.620741  \n",
       "4    7.307207   90.903285   9.534321  \n",
       "5    7.254711   86.233902   9.286221  \n",
       "6    8.192920  100.059389  10.002969  \n",
       "7    6.494264   81.432742   9.024009  \n",
       "8    7.481616   97.479091   9.873150  \n",
       "9    6.965995   81.512813   9.028445  \n",
       "10   7.234211   91.288036   9.554477  \n",
       "11   7.156755   89.985044   9.486045  \n",
       "12   7.403436   95.147501   9.754358  \n",
       "13   8.912251  122.601207  11.072543  \n",
       "14  10.548755  159.581536  12.632559  \n",
       "15  12.896794  257.342238  16.041890  \n",
       "16  14.230575  260.777117  16.148595  \n",
       "17  14.577408  273.364474  16.533737  \n",
       "18  14.518509  271.221356  16.468799  \n",
       "19  13.790661  249.219032  15.786673  \n",
       "20  14.531803  263.632176  16.236754  \n",
       "21   8.256720  112.380441  10.600964  \n",
       "22   8.958523  127.402469  11.287270  \n",
       "23   7.895857  101.761643  10.087698  \n",
       "24   6.999508  101.708064  10.085042  \n",
       "25   8.439687   91.397712   9.560215  \n",
       "26   6.262075   58.625635   7.656738  \n",
       "27   6.951790   63.185512   7.948931  \n",
       "28   4.814592   31.027856   5.570265  \n",
       "29   5.365153   34.960071   5.912704  \n",
       "30   5.558473   38.590180   6.212100  \n",
       "31   5.571360   38.331433   6.191238  \n",
       "32   5.642085   38.660956   6.217794  \n",
       "33   5.645657   38.629135   6.215234  \n",
       "34   5.777380   39.782777   6.307359  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 튜닝 후 loss 확인\n",
    "df_after = pd.read_csv(\"./data_new/lstm_결과_튜닝후.csv\")\n",
    "df_after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff234e69-b7b4-4ae3-83a9-41ccb4e2ff8f",
   "metadata": {},
   "source": [
    "손실 가중치를 준 튜닝 후, loss가 줄어들어 모델이 최적화된 것을 확인함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8a454728-778f-4ec6-83e1-e8c5e020b0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.874576</td>\n",
       "      <td>9.408555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.446987</td>\n",
       "      <td>9.684718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.963830</td>\n",
       "      <td>15.692715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.741370</td>\n",
       "      <td>9.603837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.102161</td>\n",
       "      <td>6.089528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      before      after\n",
       "0   8.874576   9.408555\n",
       "1   9.446987   9.684718\n",
       "2  15.963830  15.692715\n",
       "3   9.741370   9.603837\n",
       "4   6.102161   6.089528"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 결과를 저장할 데이터프레임\n",
    "final_rmse_df = pd.DataFrame()\n",
    "\n",
    "# 튜닝 전 rmse 확인\n",
    "result_before = df_before.groupby('part_number')['rmse'].mean().reset_index()\n",
    "\n",
    "# 결과 데이터프레임에 열 방향으로 합치기\n",
    "final_rmse_df = pd.concat([final_rmse_df, result_before['rmse']], axis=1, ignore_index=True)\n",
    "\n",
    "# 튜닝 후 rmse 확인\n",
    "result_after = df_after.groupby('part_number')['rmse'].mean().reset_index()\n",
    "\n",
    "# 결과 데이터프레임에 열 방향으로 합치기\n",
    "final_rmse_df = pd.concat([final_rmse_df, result_after['rmse']], axis=1, ignore_index=True)\n",
    "\n",
    "# 컬럼명 설정\n",
    "final_rmse_df.columns = ['before', 'after']\n",
    "\n",
    "# 저장하기\n",
    "final_rmse_df.to_csv('./data_new/lstm_튜닝전_후_rmse_평균.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 최종 결과 출력\n",
    "final_rmse_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d3f463-4e47-4a1c-9cad-2a0199253de3",
   "metadata": {},
   "source": [
    "### LSTM 튜닝 전/후 RMSE 비교 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2845be6e-3967-46be-b1a3-624bd32287df",
   "metadata": {},
   "source": [
    "```\n",
    "      before      after\n",
    "0   8.874576   9.408555\n",
    "1   9.446987   9.684718\n",
    "2  15.963830  15.692715\n",
    "3   9.741370   9.603837\n",
    "4   6.102161   6.089528\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e2eae-dbb4-4e31-92af-516440bc70a4",
   "metadata": {},
   "source": [
    "부품 6과 15의 RMSE는 증가했지만 16, 29, 94의 RMSE는 감소함<br>\n",
    "튜닝을 통해 loss를 줄일 수 있었으며, 3개의 부품에서 더 나은 결과를 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebbaa80-437f-4d4d-95a5-0470c58cc212",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb83e98-2a6e-4415-819f-719d857f14df",
   "metadata": {},
   "source": [
    "→ 03_원본데이터_오차계산 파일에서 최종 검증 진행"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_kernel",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
